{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Experiment with Various Video Stabalization Models\n",
    "\n",
    "This notebook will explore using [StabNet and the DUT](https://github.com/Annbless/DUTCode) as a potential image stabalization models. For SageMaker you will want to launch the instance as ml.g4dn.xlarge (4 vCPU + 16 GiB + 1 GPU) Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some pretrained models. So we need to look into what it actually takes to run a pytorch inference. My first work will to get the models running via an inference in a notebook.\n",
    "\n",
    "The inferences can be run using scripts/deploy_samples.sh. I've brought the code into this notebook so I can study it. to better understand what is going on and where."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running StabNet Stabalizer\n",
    "\n",
    "These qre the interesting pieces:\n",
    "\n",
    "```bash\n",
    "OutputBasePath='results/'\n",
    "StabNetPath='ckpt/stabNet.pth'\n",
    "InputPath='images/'\n",
    "```\n",
    "\n",
    "```bash\n",
    "# Run the StabNet model\n",
    "echo \" Stabiling using the StabNet model \"\n",
    "echo \"-----------------------------------\"\n",
    "\n",
    "python ./scripts/StabNetStabilizer.py \\\n",
    "    --modelPath=$StabNetPath \\\n",
    "    --OutputBasePath=$OutputBasePath \\\n",
    "    --InputBasePath=$InputPath \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So given this I will pull the code from StabNetStabilizer.py to explore it. I will modify it as needed to support running from the notebook so I can really get in and explore what is going on.\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import traceback\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "parentddir = os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir))\n",
    "sys.path.append(parentddir)\n",
    "\n",
    "from models.StabNet.v2_93 import *\n",
    "from models.StabNet.model import stabNet\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--modelPath', default='./models')\n",
    "parser.add_argument('--before-ch', type=int)\n",
    "parser.add_argument('--OutputBasePath', default='data_video_local')\n",
    "parser.add_argument('--InputBasePath', default='')\n",
    "parser.add_argument('--max-span', type=int, default=1)\n",
    "parser.add_argument('--refine', type=int, default=1)\n",
    "parser.add_argument('--no_bm', type=int, default=1)\n",
    "args = parser.parse_args()\n",
    "\n",
    "MaxSpan = args.max_span\n",
    "args.indices = indices[1:]\n",
    "batch_size = 1\n",
    "\n",
    "before_ch = max(args.indices)#args.before_ch\n",
    "after_ch = max(1, -min(args.indices) + 1)\n",
    "\n",
    "model = stabNet()\n",
    "r_model = torch.load(args.modelPath)\n",
    "model.load_state_dict(r_model)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "def cvt_img2train(img, crop_rate = 1):\n",
    "    img = Image.fromarray(cv2.cvtColor(img,cv2.COLOR_BGR2GRAY))\n",
    "    if (crop_rate != 1):\n",
    "        h = int(height / crop_rate)\n",
    "        dh = int((h - height) / 2)\n",
    "        w = int(width / crop_rate)\n",
    "        dw = int((w - width) / 2)\n",
    "\n",
    "        img = img.resize((w, h), Image.BILINEAR)\n",
    "        img = img.crop((dw, dh, dw + width, dh + height))\n",
    "    else:\n",
    "        img = img.resize((width, height), Image.BILINEAR)\n",
    "    img = np.array(img)\n",
    "    img = img * (1. / 255) - 0.5\n",
    "    img = img.reshape((1, height, width, 1))\n",
    "    return img\n",
    "\n",
    "def make_dirs(path):\n",
    "    if not os.path.exists(path): os.makedirs(path)\n",
    "\n",
    "cvt_train2img = lambda x: ((np.reshape(x, (height, width)) + 0.5) * 255).astype(np.uint8)\n",
    "\n",
    "def warpRevBundle2(img, x_map, y_map):\n",
    "    assert(img.ndim == 3)\n",
    "    assert(img.shape[-1] == 3)\n",
    "    rate = 4\n",
    "    x_map = cv2.resize(cv2.resize(x_map, (int(width / rate), int(height / rate))), (width, height))\n",
    "    y_map = cv2.resize(cv2.resize(y_map, (int(width / rate), int(height / rate))), (width, height))\n",
    "    x_map = (x_map + 1) / 2 * width\n",
    "    y_map = (y_map + 1) / 2 * height\n",
    "    dst = cv2.remap(img, x_map, y_map, cv2.INTER_LINEAR)\n",
    "    assert(dst.shape == (height, width, 3))\n",
    "    return dst\n",
    "\n",
    "production_dir = args.OutputBasePath\n",
    "make_dirs(production_dir)\n",
    "\n",
    "image_len = len([ele for ele in os.listdir(args.InputBasePath) if ele[-4:] == '.jpg'])\n",
    "images = []\n",
    "\n",
    "for i in range(image_len):\n",
    "\n",
    "    image = cv2.imread(os.path.join(args.InputBasePath, '{}.jpg'.format(i)))\n",
    "    image = cv2.resize(image, (width, height))\n",
    "    images.append(image)\n",
    "\n",
    "print('inference with {}'.format(args.indices))\n",
    "\n",
    "tot_time = 0\n",
    "\n",
    "print('totally {} frames for stabilization'.format(len(images)))\n",
    "\n",
    "before_frames = []\n",
    "before_masks = []\n",
    "after_frames = []\n",
    "after_temp = []\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "frame = images[cnt]\n",
    "\n",
    "cnt += 1\n",
    "\n",
    "for i in range(before_ch):\n",
    "    before_frames.append(cvt_img2train(frame, crop_rate))\n",
    "    before_masks.append(np.zeros([1, height, width, 1], dtype=np.float))\n",
    "    temp = before_frames[i]\n",
    "    temp = ((np.reshape(temp, (height, width)) + 0.5) * 255).astype(np.uint8)\n",
    "\n",
    "    temp = np.concatenate([temp, np.zeros_like(temp)], axis=1)\n",
    "    temp = np.concatenate([temp, np.zeros_like(temp)], axis=0)\n",
    "\n",
    "\n",
    "for i in range(after_ch):\n",
    "    frame = images[cnt]\n",
    "    cnt = cnt + 1\n",
    "    frame_unstable = frame\n",
    "    after_temp.append(frame)\n",
    "    after_frames.append(cvt_img2train(frame, 1))\n",
    "\n",
    "length = 0\n",
    "in_xs = []\n",
    "delta = 0\n",
    "\n",
    "dh = int(height * 0.8 / 2)\n",
    "dw = int(width * 0.8 / 2)\n",
    "all_black = np.zeros([height, width], dtype=np.int64)\n",
    "frames = []\n",
    "\n",
    "black_mask = np.zeros([dh, width], dtype=np.float)\n",
    "temp_mask = np.concatenate([np.zeros([height - 2 * dh, dw], dtype=np.float), np.ones([height - 2 * dh, width - 2 * dw], dtype=np.float), np.zeros([height - 2 * dh, dw], dtype=np.float)], axis=1)\n",
    "black_mask = np.reshape(np.concatenate([black_mask, temp_mask, black_mask], axis=0),[1, height, width, 1]) \n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "\n",
    "        in_x = []\n",
    "        if input_mask:\n",
    "            for i in args.indices:\n",
    "                if (i > 0):\n",
    "                    in_x.append(before_masks[-i])\n",
    "        for i in args.indices:\n",
    "            if (i > 0):\n",
    "                in_x.append(before_frames[-i])\n",
    "        in_x.append(after_frames[0])\n",
    "        for i in args.indices:\n",
    "            if (i < 0):\n",
    "                in_x.append(after_frames[-i])\n",
    "        if (args.no_bm == 0):\n",
    "            in_x.append(black_mask)\n",
    "        # for i in range(after_ch + 1):\n",
    "        in_x = np.concatenate(in_x, axis = 3)\n",
    "        # for max span\n",
    "        if MaxSpan != 1:\n",
    "            in_xs.append(in_x)\n",
    "            if len(in_xs) > MaxSpan: \n",
    "                in_xs = in_xs[-1:]\n",
    "                print('cut')\n",
    "            in_x = in_xs[0].copy()\n",
    "            in_x[0, ..., before_ch] = after_frames[0][..., 0]\n",
    "        tmp_in_x = np.array(in_x.copy())\n",
    "        for j in range(args.refine):\n",
    "            start = time.time()\n",
    "            img, black, x_map_, y_map_ = model.forward(torch.Tensor(tmp_in_x.transpose((0, 3, 1, 2))).cuda())\n",
    "            img = img.cpu().clone().detach().numpy()\n",
    "            black = black.cpu().clone().detach().numpy()\n",
    "            x_map_ = x_map_.cpu().clone().detach().numpy()\n",
    "            y_map_ = y_map_.cpu().clone().detach().numpy()\n",
    "            tot_time += time.time() - start\n",
    "            black = black[0, :, :]\n",
    "            xmap = x_map_[0, :, :, 0]\n",
    "            ymap = y_map_[0, :, :, 0]\n",
    "            all_black = all_black + np.round(black).astype(np.int64)\n",
    "            img = img[0, :, :, :].reshape(height, width)\n",
    "            frame = img + black * (-1)\n",
    "            frame = frame.reshape(1, height, width, 1)\n",
    "            tmp_in_x[..., -1] = frame[..., 0]\n",
    "        img = ((np.reshape(img + 0.5, (height, width))) * 255).astype(np.uint8)\n",
    "        \n",
    "        net_output = img\n",
    "\n",
    "        img_warped = warpRevBundle2(cv2.resize(after_temp[0], (width, height)), xmap, ymap)\n",
    "        frames.append(img_warped)\n",
    "\n",
    "        if cnt + 1 <= len(images):\n",
    "            frame_unstable = images[cnt]\n",
    "            cnt = cnt + 1\n",
    "            ret = True\n",
    "        else:\n",
    "            ret = False  \n",
    "        \n",
    "        if (not ret):\n",
    "            break\n",
    "        length = length + 1\n",
    "        if (length % 10 == 0):\n",
    "            print(\"length: \" + str(length))      \n",
    "            print('fps={}'.format(length / tot_time))\n",
    "\n",
    "        before_frames.append(frame)\n",
    "        before_masks.append(black.reshape((1, height, width, 1)))\n",
    "        before_frames.pop(0)\n",
    "        before_masks.pop(0)\n",
    "        after_frames.append(cvt_img2train(frame_unstable, 1))\n",
    "        after_frames.pop(0)\n",
    "        after_temp.append(frame_unstable)\n",
    "        after_temp.pop(0)\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    print('total length={}'.format(length + 2))\n",
    "\n",
    "    black_sum = np.zeros([height + 1, width + 1], dtype=np.int64)\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            black_sum[i + 1][j + 1] = black_sum[i][j + 1] + black_sum[i + 1][j] - black_sum[i][j] + all_black[i][j]\n",
    "    max_s = 0\n",
    "    ans = []\n",
    "    for i in range(0, int(math.floor(height * 0.5)), 10):\n",
    "        print(i)\n",
    "        print(max_s)\n",
    "        for j in range(0, int(math.floor(width * 0.5)), 10):\n",
    "            if (all_black[i][j] > 0):\n",
    "                continue\n",
    "            for hh in range(i, height):\n",
    "                dw = int(math.floor(float(max_s) / (hh - i + 1)))\n",
    "                for ww in range(j, width):\n",
    "                    if (black_sum[hh + 1][ww + 1] - black_sum[hh + 1][j] - black_sum[i][ww + 1] + black_sum[i][j] > 0):\n",
    "                        break\n",
    "                    else:\n",
    "                        s = (hh - i + 1) * (ww - j + 1)\n",
    "                        if (s > max_s):\n",
    "                            max_s = s\n",
    "                            ans = [i, j, hh, ww]\n",
    "    videoWriter = cv2.VideoWriter(os.path.join(production_dir, 'StabNet_stable.mp4'), \n",
    "        cv2.VideoWriter_fourcc(*'MP4V'), 25, (ans[3] - ans[1] + 1, ans[2] - ans[0] + 1))\n",
    "    for frame in frames:\n",
    "        frame_ = frame[ans[0]:ans[2] + 1, ans[1]:ans[3] + 1, :]\n",
    "        videoWriter.write(frame_)\n",
    "    videoWriter.release()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget: /opt/conda/lib/libuuid.so.1: no version information available (required by wget)\n",
      "--2021-09-08 21:06:10--  https://johnvansickle.com/ffmpeg/releases/ffmpeg-release-amd64-static.tar.xz\n",
      "Resolving johnvansickle.com (johnvansickle.com)... 107.180.57.212\n",
      "Connecting to johnvansickle.com (johnvansickle.com)|107.180.57.212|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 39577132 (38M) [application/x-xz]\n",
      "Saving to: ‘ffmpeg-release-amd64-static.tar.xz’\n",
      "\n",
      "ffmpeg-release-amd6 100%[===================>]  37.74M  17.5MB/s    in 2.2s    \n",
      "\n",
      "2021-09-08 21:06:12 (17.5 MB/s) - ‘ffmpeg-release-amd64-static.tar.xz’ saved [39577132/39577132]\n",
      "\n",
      "tar: ffmpeg-4.4-amd64-static/GPLv3.txt: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/manpages/ffmpeg-all.txt: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/manpages/ffmpeg-scaler.txt: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/manpages/ffmpeg-resampler.txt: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/manpages/ffmpeg-filters.txt: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/manpages/ffprobe.txt: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/manpages/ffmpeg-devices.txt: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/manpages/ffmpeg-utils.txt: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/manpages/ffmpeg-protocols.txt: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/manpages/ffmpeg-codecs.txt: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/manpages/ffmpeg-bitstream-filters.txt: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/manpages/ffmpeg.txt: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/manpages/ffmpeg-formats.txt: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/manpages: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/ffprobe: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/qt-faststart: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_v0.6.1.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_v0.6.1.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0020.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0005: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0015: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0016.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0008.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0020: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0017.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0014: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0011: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0012: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0004: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0005.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0013.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0007.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0001: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0009: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0009.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0004.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0019.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0007: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0006: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0017: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0011.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0008: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0010: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0018: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0002.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0012.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0003.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0019: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0014.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0018.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0016: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0010.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0001.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0003: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0015.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0013: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0006.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3/vmaf_rb_v0.6.3.pkl.0002: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.3: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0019.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0005.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0004: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0015: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0010.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0012.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0005: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0008.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0009: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0018: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0015.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0011: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0014.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0012: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0003.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0006.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0013.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0001: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0011.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0007: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0006: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0017: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0008: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0003: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0002: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0004.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0001.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0018.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0002.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0014: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0017.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0019: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0009.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0013: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0007.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0016.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0010: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2/vmaf_rb_v0.6.2.pkl.0016: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_rb_v0.6.2: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/000-PLEASE-README.TXT: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0008.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0012: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0002.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0007.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0011.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0019: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0017.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0017: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0009: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0010: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0005.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0009.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0013: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0018: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0013.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0014: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0004: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0006.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0005: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0007: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0019.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0015.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0010.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0008: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0004.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0006: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0001.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0016.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0015: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0003.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0011: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0016: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0003: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0014.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0018.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0001: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0002: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2/vmaf_4k_rb_v0.6.2.pkl.0012.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_rb_v0.6.2: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_v0.6.1neg.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0012.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0005: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0020.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0009: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0014: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0001.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0019.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0010.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0009.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0010: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0012: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0013: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0016.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0014.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0019: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0015: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0006: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0007.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0002.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0004.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0011.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0006.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0018: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0008.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0018.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0011: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0007: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0020: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0003.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0013.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0005.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0001: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0016: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0008: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0003: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0004: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0017.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0002: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0015.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3/vmaf_b_v0.6.3.pkl.0017: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_b_v0.6.3: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxall_vmafv2.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/vmaf_v0.6.0.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflx_vmaff_rf_v2.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxtrain_vmafv2.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxtrain_vmafv3.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/niqe_v0.1.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxtrain_libsvmnusvr_currentbest.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxall_vmafv3.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxall_vmafv1.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflx_v1.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/vmaf_4k_v0.6.1rc.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxall_vmafv4.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/vmaf_4k_v0.6.1rc.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflx_v1.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxtrain_vmafv1.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxall_vmafv4.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxtrain_vmafv1.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxall_libsvmnusvr_currentbest.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxtrain_vmafv3a.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxtrain_vmafv3.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxtrain_norm_type_none.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/vmaf_v0.6.0.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxall_vmafv3a.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxall_vmafv1.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxall_vmafv3.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxtrain_libsvmnusvr_currentbest.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxall_libsvmnusvr_currentbest.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflx_vmaff_rf_v1.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxtrain_vmafv2.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxall_vmafv2.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/model_V8a.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxtrain_norm_type_none.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxtrain_vmafv3a.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models/nflxall_vmafv3a.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/other_models: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_4k_v0.6.1.pkl.model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_v0.6.1.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model/vmaf_v0.6.1neg.pkl: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/model: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/readme.txt: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static/ffmpeg: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: ffmpeg-4.4-amd64-static: Cannot change ownership to uid 1000, gid 1000: Operation not permitted\n",
      "tar: Exiting with failure status due to previous errors\n",
      "ffmpeg version 4.4-static https://johnvansickle.com/ffmpeg/  Copyright (c) 2000-2021 the FFmpeg developers\n",
      "built with gcc 8 (Debian 8.3.0-6)\n",
      "configuration: --enable-gpl --enable-version3 --enable-static --disable-debug --disable-ffplay --disable-indev=sndio --disable-outdev=sndio --cc=gcc --enable-fontconfig --enable-frei0r --enable-gnutls --enable-gmp --enable-libgme --enable-gray --enable-libaom --enable-libfribidi --enable-libass --enable-libvmaf --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librubberband --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libvorbis --enable-libopus --enable-libtheora --enable-libvidstab --enable-libvo-amrwbenc --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libdav1d --enable-libxvid --enable-libzvbi --enable-libzimg\n",
      "libavutil      56. 70.100 / 56. 70.100\n",
      "libavcodec     58.134.100 / 58.134.100\n",
      "libavformat    58. 76.100 / 58. 76.100\n",
      "libavdevice    58. 13.100 / 58. 13.100\n",
      "libavfilter     7.110.100 /  7.110.100\n",
      "libswscale      5.  9.100 /  5.  9.100\n",
      "libswresample   3.  9.100 /  3.  9.100\n",
      "libpostproc    55.  9.100 / 55.  9.100\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.6/site-packages (21.2.4)\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.6/site-packages (0.17.2)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (2020.9.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (8.2.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (1.5.4)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (3.3.4)\n",
      "Requirement already satisfied: numpy>=1.15.1 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (1.19.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (2.5.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.16.0)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.0->scikit-image) (4.4.0)\n",
      "Requirement already satisfied: easydict in /opt/conda/lib/python3.6/site-packages (1.9)\n",
      "Requirement already satisfied: pypng in /opt/conda/lib/python3.6/site-packages (0.0.21)\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: | \n",
      "Warning: 2 possible package resolutions (only showing differing packages):\n",
      "  - defaults/linux-64::decorator-4.4.0-py36_1, defaults/noarch::networkx-2.5.1-pyhd3eb1b0_0\n",
      "  - defaults/linux-64::networkx-2.2-py36_1, defaults/noarch::decorator-5.0.9-pyhd3eb1b0done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - conda\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    fastrlock-0.6              |   py36h2531618_0          30 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:          30 KB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2021.5.3~ --> pkgs/main::ca-certificates-2021.7.5-h06a4308_1\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            conda-forge::certifi-2021.5.30-py36h5~ --> pkgs/main::certifi-2021.5.30-py36h06a4308_0\n",
      "  conda              conda-forge::conda-4.10.3-py36h5fab9b~ --> pkgs/main::conda-4.10.3-py36h06a4308_0\n",
      "  fastrlock          conda-forge::fastrlock-0.6-py36hc4f0c~ --> pkgs/main::fastrlock-0.6-py36h2531618_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "fastrlock-0.6        | 30 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - cupy\n",
      "\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2021.7.5-h~ --> conda-forge::ca-certificates-2021.5.30-ha878542_0\n",
      "  certifi            pkgs/main::certifi-2021.5.30-py36h06a~ --> conda-forge::certifi-2021.5.30-py36h5fab9bb_0\n",
      "  conda              pkgs/main::conda-4.10.3-py36h06a4308_0 --> conda-forge::conda-4.10.3-py36h5fab9bb_0\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "FFMPEG_TAR = 'ffmpeg-release-amd64-static.tar.xz'\n",
    "if os.path.exists(FFMPEG_TAR):\n",
    "    os.remove(FFMPEG_TAR)\n",
    "    \n",
    "!wget https://johnvansickle.com/ffmpeg/releases/ffmpeg-release-amd64-static.tar.xz\n",
    "!tar -xf ffmpeg-release-amd64-static.tar.xz\n",
    "!ffmpeg-4.4-amd64-static/ffmpeg -version\n",
    "\n",
    "if os.path.exists(FFMPEG_TAR):\n",
    "    os.remove(FFMPEG_TAR)\n",
    "\n",
    "!/opt/conda/bin/python -m pip install --upgrade pip\n",
    "!pip install scikit-image\n",
    "!pip install easydict\n",
    "!pip install pypng\n",
    "\n",
    "!conda update -n base -y -c defaults conda\n",
    "!conda install -y -c conda-forge cupy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Exploration of Pytorch version of StabNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/hand-tracking-stabilization'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import traceback\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "\n",
    "project_location = os.getcwd()\n",
    "sys.path.append(os.path.join(project_location,'DUTCode'))\n",
    "project_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.StabNet.v2_93 import *\n",
    "from models.StabNet.model import stabNet\n",
    "\n",
    "#help(stabNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Pre-trained Models from S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I pulled the pre-trained models to S3 to protect them from disappearing. At the time the pre-trained models were at [https://drive.google.com/drive/folders/15T8Wwf1OL99AKDGTgECzwubwTqbkmGn6](https://drive.google.com/drive/folders/15T8Wwf1OL99AKDGTgECzwubwTqbkmGn6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.85 s, sys: 1.16 s, total: 4.02 s\n",
      "Wall time: 7.54 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/root/hand-tracking-stabilization'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "\n",
    "project_dir = os.getcwd()\n",
    "\n",
    "data_dir = 'DUTPretrained'\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "os.chdir(data_dir)\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file('madat-machine-learning-data', 'Mark/capstone-project/pre-trained-models/ckpt-20210817T154228Z-001.zip', 'ckpt-20210817T154228Z-001.zip')\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile('ckpt-20210817T154228Z-001.zip', 'r') as zipObj:\n",
    "    zipObj.extractall()\n",
    "    \n",
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1, [1, 2, 4, 8, 16, 32])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From deploy_samples.sh\n",
    "\n",
    "#OutputBasePath='results/'\n",
    "#StabNetPath='ckpt/stabNet.pth'\n",
    "#InputPath='images/'\n",
    "\n",
    "#--modelPath=$StabNetPath \\\n",
    "#--OutputBasePath=$OutputBasePath \\\n",
    "#--InputBasePath=$InputPath \n",
    "class Arguments:\n",
    "    \n",
    "    modelPath = 'DUTPretrained/ckpt/stabNet.pth'\n",
    "    before_ch = 0\n",
    "    OutputBasePath = 'results/'\n",
    "    InputBasePath = 'DUTCode/images/'\n",
    "    max_span = 1\n",
    "    refine = 1\n",
    "    no_bm=1\n",
    "    \n",
    "args = Arguments()\n",
    "\n",
    "MaxSpan = args.max_span\n",
    "batch_size = 1\n",
    "\n",
    "# WATCH FOR THESE: Not sure what these are used for. \n",
    "args.indices = indices[1:]\n",
    "before_ch = max(args.indices)#args.before_ch\n",
    "after_ch = max(1, -min(args.indices) + 1)\n",
    "\n",
    "before_ch, after_ch, args.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stabNet(\n",
       "  (resnet50): KitModel(\n",
       "    (resnet_v2_50_conv1_Conv2D): Conv2d(13, 64, kernel_size=(7, 7), stride=(2, 2))\n",
       "    (resnet_v2_50_block1_unit_1_bottleneck_v2_preact_FusedBatchNorm): BatchNorm2d(64, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block1_unit_1_bottleneck_v2_shortcut_Conv2D): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (resnet_v2_50_block1_unit_1_bottleneck_v2_conv1_Conv2D): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block1_unit_1_bottleneck_v2_conv1_BatchNorm_FusedBatchNorm): BatchNorm2d(64, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block1_unit_1_bottleneck_v2_conv2_Conv2D): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block1_unit_1_bottleneck_v2_conv2_BatchNorm_FusedBatchNorm): BatchNorm2d(64, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block1_unit_1_bottleneck_v2_conv3_Conv2D): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (resnet_v2_50_block1_unit_2_bottleneck_v2_preact_FusedBatchNorm): BatchNorm2d(256, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block1_unit_2_bottleneck_v2_conv1_Conv2D): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block1_unit_2_bottleneck_v2_conv1_BatchNorm_FusedBatchNorm): BatchNorm2d(64, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block1_unit_2_bottleneck_v2_conv2_Conv2D): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block1_unit_2_bottleneck_v2_conv2_BatchNorm_FusedBatchNorm): BatchNorm2d(64, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block1_unit_2_bottleneck_v2_conv3_Conv2D): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (resnet_v2_50_block1_unit_3_bottleneck_v2_preact_FusedBatchNorm): BatchNorm2d(256, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block1_unit_3_bottleneck_v2_conv1_Conv2D): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block1_unit_3_bottleneck_v2_conv1_BatchNorm_FusedBatchNorm): BatchNorm2d(64, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block1_unit_3_bottleneck_v2_conv2_Conv2D): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (resnet_v2_50_block1_unit_3_bottleneck_v2_conv2_BatchNorm_FusedBatchNorm): BatchNorm2d(64, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block1_unit_3_bottleneck_v2_conv3_Conv2D): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (resnet_v2_50_block2_unit_1_bottleneck_v2_preact_FusedBatchNorm): BatchNorm2d(256, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block2_unit_1_bottleneck_v2_shortcut_Conv2D): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (resnet_v2_50_block2_unit_1_bottleneck_v2_conv1_Conv2D): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block2_unit_1_bottleneck_v2_conv1_BatchNorm_FusedBatchNorm): BatchNorm2d(128, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block2_unit_1_bottleneck_v2_conv2_Conv2D): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block2_unit_1_bottleneck_v2_conv2_BatchNorm_FusedBatchNorm): BatchNorm2d(128, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block2_unit_1_bottleneck_v2_conv3_Conv2D): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (resnet_v2_50_block2_unit_2_bottleneck_v2_preact_FusedBatchNorm): BatchNorm2d(512, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block2_unit_2_bottleneck_v2_conv1_Conv2D): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block2_unit_2_bottleneck_v2_conv1_BatchNorm_FusedBatchNorm): BatchNorm2d(128, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block2_unit_2_bottleneck_v2_conv2_Conv2D): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block2_unit_2_bottleneck_v2_conv2_BatchNorm_FusedBatchNorm): BatchNorm2d(128, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block2_unit_2_bottleneck_v2_conv3_Conv2D): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (resnet_v2_50_block2_unit_3_bottleneck_v2_preact_FusedBatchNorm): BatchNorm2d(512, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block2_unit_3_bottleneck_v2_conv1_Conv2D): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block2_unit_3_bottleneck_v2_conv1_BatchNorm_FusedBatchNorm): BatchNorm2d(128, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block2_unit_3_bottleneck_v2_conv2_Conv2D): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block2_unit_3_bottleneck_v2_conv2_BatchNorm_FusedBatchNorm): BatchNorm2d(128, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block2_unit_3_bottleneck_v2_conv3_Conv2D): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (resnet_v2_50_block2_unit_4_bottleneck_v2_preact_FusedBatchNorm): BatchNorm2d(512, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block2_unit_4_bottleneck_v2_conv1_Conv2D): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block2_unit_4_bottleneck_v2_conv1_BatchNorm_FusedBatchNorm): BatchNorm2d(128, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block2_unit_4_bottleneck_v2_conv2_Conv2D): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (resnet_v2_50_block2_unit_4_bottleneck_v2_conv2_BatchNorm_FusedBatchNorm): BatchNorm2d(128, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block2_unit_4_bottleneck_v2_conv3_Conv2D): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (resnet_v2_50_block3_unit_1_bottleneck_v2_preact_FusedBatchNorm): BatchNorm2d(512, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block3_unit_1_bottleneck_v2_shortcut_Conv2D): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (resnet_v2_50_block3_unit_1_bottleneck_v2_conv1_Conv2D): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block3_unit_1_bottleneck_v2_conv1_BatchNorm_FusedBatchNorm): BatchNorm2d(256, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block3_unit_1_bottleneck_v2_conv2_Conv2D): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block3_unit_1_bottleneck_v2_conv2_BatchNorm_FusedBatchNorm): BatchNorm2d(256, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block3_unit_1_bottleneck_v2_conv3_Conv2D): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (resnet_v2_50_block3_unit_2_bottleneck_v2_preact_FusedBatchNorm): BatchNorm2d(1024, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block3_unit_2_bottleneck_v2_conv1_Conv2D): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block3_unit_2_bottleneck_v2_conv1_BatchNorm_FusedBatchNorm): BatchNorm2d(256, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block3_unit_2_bottleneck_v2_conv2_Conv2D): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block3_unit_2_bottleneck_v2_conv2_BatchNorm_FusedBatchNorm): BatchNorm2d(256, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block3_unit_2_bottleneck_v2_conv3_Conv2D): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (resnet_v2_50_block3_unit_3_bottleneck_v2_preact_FusedBatchNorm): BatchNorm2d(1024, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block3_unit_3_bottleneck_v2_conv1_Conv2D): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block3_unit_3_bottleneck_v2_conv1_BatchNorm_FusedBatchNorm): BatchNorm2d(256, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block3_unit_3_bottleneck_v2_conv2_Conv2D): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block3_unit_3_bottleneck_v2_conv2_BatchNorm_FusedBatchNorm): BatchNorm2d(256, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block3_unit_3_bottleneck_v2_conv3_Conv2D): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (resnet_v2_50_block3_unit_4_bottleneck_v2_preact_FusedBatchNorm): BatchNorm2d(1024, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block3_unit_4_bottleneck_v2_conv1_Conv2D): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block3_unit_4_bottleneck_v2_conv1_BatchNorm_FusedBatchNorm): BatchNorm2d(256, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block3_unit_4_bottleneck_v2_conv2_Conv2D): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block3_unit_4_bottleneck_v2_conv2_BatchNorm_FusedBatchNorm): BatchNorm2d(256, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block3_unit_4_bottleneck_v2_conv3_Conv2D): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (resnet_v2_50_block3_unit_5_bottleneck_v2_preact_FusedBatchNorm): BatchNorm2d(1024, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block3_unit_5_bottleneck_v2_conv1_Conv2D): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block3_unit_5_bottleneck_v2_conv1_BatchNorm_FusedBatchNorm): BatchNorm2d(256, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block3_unit_5_bottleneck_v2_conv2_Conv2D): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block3_unit_5_bottleneck_v2_conv2_BatchNorm_FusedBatchNorm): BatchNorm2d(256, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block3_unit_5_bottleneck_v2_conv3_Conv2D): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (resnet_v2_50_block3_unit_6_bottleneck_v2_preact_FusedBatchNorm): BatchNorm2d(1024, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block3_unit_6_bottleneck_v2_conv1_Conv2D): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block3_unit_6_bottleneck_v2_conv1_BatchNorm_FusedBatchNorm): BatchNorm2d(256, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block3_unit_6_bottleneck_v2_conv2_Conv2D): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (resnet_v2_50_block3_unit_6_bottleneck_v2_conv2_BatchNorm_FusedBatchNorm): BatchNorm2d(256, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block3_unit_6_bottleneck_v2_conv3_Conv2D): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (resnet_v2_50_block4_unit_1_bottleneck_v2_preact_FusedBatchNorm): BatchNorm2d(1024, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block4_unit_1_bottleneck_v2_shortcut_Conv2D): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (resnet_v2_50_block4_unit_1_bottleneck_v2_conv1_Conv2D): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block4_unit_1_bottleneck_v2_conv1_BatchNorm_FusedBatchNorm): BatchNorm2d(512, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block4_unit_1_bottleneck_v2_conv2_Conv2D): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block4_unit_1_bottleneck_v2_conv2_BatchNorm_FusedBatchNorm): BatchNorm2d(512, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block4_unit_1_bottleneck_v2_conv3_Conv2D): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (resnet_v2_50_block4_unit_2_bottleneck_v2_preact_FusedBatchNorm): BatchNorm2d(2048, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block4_unit_2_bottleneck_v2_conv1_Conv2D): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block4_unit_2_bottleneck_v2_conv1_BatchNorm_FusedBatchNorm): BatchNorm2d(512, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block4_unit_2_bottleneck_v2_conv2_Conv2D): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block4_unit_2_bottleneck_v2_conv2_BatchNorm_FusedBatchNorm): BatchNorm2d(512, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block4_unit_2_bottleneck_v2_conv3_Conv2D): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (resnet_v2_50_block4_unit_3_bottleneck_v2_preact_FusedBatchNorm): BatchNorm2d(2048, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block4_unit_3_bottleneck_v2_conv1_Conv2D): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block4_unit_3_bottleneck_v2_conv1_BatchNorm_FusedBatchNorm): BatchNorm2d(512, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block4_unit_3_bottleneck_v2_conv2_Conv2D): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (resnet_v2_50_block4_unit_3_bottleneck_v2_conv2_BatchNorm_FusedBatchNorm): BatchNorm2d(512, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_block4_unit_3_bottleneck_v2_conv3_Conv2D): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (resnet_v2_50_postnorm_FusedBatchNorm): BatchNorm2d(2048, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
       "    (resnet_v2_50_logits_Conv2D): Conv2d(2048, 1001, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (regressor): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=512, out_features=50, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = stabNet()\n",
    "r_model = torch.load(args.modelPath)\n",
    "model.load_state_dict(r_model)\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference with [1, 2, 4, 8, 16, 32]\n",
      "totally 480 frames for stabilization\n",
      "[2021-09-08 21:07:12.824 pytorch-1-6-gpu-py3-ml-g4dn-xlarge-594def216eaae0b31fbf025840e5:4025 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2021-09-08 21:07:12.911 pytorch-1-6-gpu-py3-ml-g4dn-xlarge-594def216eaae0b31fbf025840e5:4025 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "length: 10\n",
      "fps=1.6208877013374174\n",
      "length: 20\n",
      "fps=2.9592381438328204\n",
      "length: 30\n",
      "fps=4.081515932912033\n",
      "length: 40\n",
      "fps=5.040014683956966\n",
      "length: 50\n",
      "fps=5.865948430498416\n",
      "length: 60\n",
      "fps=6.5900198131433765\n",
      "length: 70\n",
      "fps=7.227461575660989\n",
      "length: 80\n",
      "fps=7.792907440035924\n",
      "length: 90\n",
      "fps=8.297485019515678\n",
      "length: 100\n",
      "fps=8.75209073002504\n",
      "length: 110\n",
      "fps=9.159254882889485\n",
      "length: 120\n",
      "fps=9.531647451642298\n",
      "length: 130\n",
      "fps=9.870204863499486\n",
      "length: 140\n",
      "fps=10.180722996010047\n",
      "length: 150\n",
      "fps=10.449978923832168\n",
      "length: 160\n",
      "fps=10.705428023051246\n",
      "length: 170\n",
      "fps=10.946600113271552\n",
      "length: 180\n",
      "fps=11.168922502109998\n",
      "length: 190\n",
      "fps=11.377922841355671\n",
      "length: 200\n",
      "fps=11.574015486643246\n",
      "length: 210\n",
      "fps=11.757661084627493\n",
      "length: 220\n",
      "fps=11.928962635415191\n",
      "length: 230\n",
      "fps=12.090176640742595\n",
      "length: 240\n",
      "fps=12.239604109313133\n",
      "length: 250\n",
      "fps=12.382788455930251\n",
      "length: 260\n",
      "fps=12.517509026366808\n",
      "length: 270\n",
      "fps=12.64436007765516\n",
      "length: 280\n",
      "fps=12.764862209163029\n",
      "length: 290\n",
      "fps=12.876625837250574\n",
      "length: 300\n",
      "fps=12.980417825272223\n",
      "length: 310\n",
      "fps=13.082841384696868\n",
      "length: 320\n",
      "fps=13.181381053817695\n",
      "length: 330\n",
      "fps=13.27222401812107\n",
      "length: 340\n",
      "fps=13.35590549657537\n",
      "length: 350\n",
      "fps=13.441345365128434\n",
      "length: 360\n",
      "fps=13.523041508744793\n",
      "length: 370\n",
      "fps=13.600549956006796\n",
      "length: 380\n",
      "fps=13.676021733423982\n",
      "length: 390\n",
      "fps=13.74521302901603\n",
      "length: 400\n",
      "fps=13.812260884949719\n",
      "length: 410\n",
      "fps=13.876369487523688\n",
      "length: 420\n",
      "fps=13.94056754259412\n",
      "length: 430\n",
      "fps=13.997405814640583\n",
      "length: 440\n",
      "fps=14.055628274922956\n",
      "length: 450\n",
      "fps=14.112930870710555\n",
      "length: 460\n",
      "fps=14.167635381086425\n",
      "length: 470\n",
      "fps=14.219649816063862\n",
      "total length=480\n",
      "0\n",
      "0\n",
      "10\n",
      "0\n",
      "20\n",
      "0\n",
      "30\n",
      "0\n",
      "40\n",
      "0\n",
      "50\n",
      "43632\n",
      "60\n",
      "70452\n",
      "70\n",
      "70452\n",
      "80\n",
      "70452\n",
      "90\n",
      "70452\n",
      "100\n",
      "70452\n",
      "110\n",
      "70452\n",
      "120\n",
      "70452\n",
      "130\n",
      "70452\n",
      "140\n",
      "70452\n",
      "Frame shape: 206 342 3\n",
      "ffmpeg version 4.4-static https://johnvansickle.com/ffmpeg/  Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 8 (Debian 8.3.0-6)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-debug --disable-ffplay --disable-indev=sndio --disable-outdev=sndio --cc=gcc --enable-fontconfig --enable-frei0r --enable-gnutls --enable-gmp --enable-libgme --enable-gray --enable-libaom --enable-libfribidi --enable-libass --enable-libvmaf --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librubberband --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libvorbis --enable-libopus --enable-libtheora --enable-libvidstab --enable-libvo-amrwbenc --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libdav1d --enable-libxvid --enable-libzvbi --enable-libzimg\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'results/temp_StabNet_stable.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf58.12.100\n",
      "  Duration: 00:00:19.16, start: 0.000000, bitrate: 937 kb/s\n",
      "  Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 342x206 [SAR 1:1 DAR 171:103], 935 kb/s, 25 fps, 25 tbr, 12800 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0mprofile High, level 1.3, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0m264 - core 161 r3048 b86ae3c - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=6 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'results/StabNet_stable.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 342x206 [SAR 1:1 DAR 171:103], q=2-31, 25 fps, 12800 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  479 fps=327 q=-1.0 Lsize=     619kB time=00:00:19.04 bitrate= 266.4kbits/s speed=  13x    \n",
      "video:614kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.892036%\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0mframe I:2     Avg QP:23.18  size:  5806\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0mframe P:260   Avg QP:25.12  size:  1888\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0mframe B:217   Avg QP:28.71  size:   577\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0mconsecutive B-frames: 33.0% 14.2% 16.9% 35.9%\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0mmb I  I16..4:  6.6% 77.1% 16.3%\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0mmb P  I16..4:  1.5%  6.9%  1.1%  P16..4: 45.7% 19.6% 11.0%  0.0%  0.0%    skip:14.1%\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0mmb B  I16..4:  0.4%  1.4%  0.1%  B16..8: 45.7%  7.8%  1.7%  direct: 1.4%  skip:41.5%  L0:45.3% L1:40.6% BI:14.1%\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0m8x8 transform intra:72.6% inter:70.7%\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0mcoded y,uvDC,uvAC intra: 60.3% 45.4% 12.1% inter: 21.3% 14.1% 1.2%\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0mi16 v,h,dc,p:  9% 64% 17% 10%\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu:  7% 53% 27%  1%  2%  2%  2%  1%  4%\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 11% 48% 16%  3%  4%  5%  4%  3%  5%\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0mi8c dc,h,v,p: 54% 32% 11%  2%\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0mref P L0: 69.7% 17.3%  9.7%  3.2%\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0mref B L0: 92.3%  6.4%  1.3%\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0mref B L1: 98.3%  1.7%\n",
      "\u001b[1;36m[libx264 @ 0x6412d80] \u001b[0mkb/s:262.07\n"
     ]
    }
   ],
   "source": [
    "tmp_stable_video_filename = 'temp_StabNet_stable.mp4'\n",
    "stable_video_filename = 'StabNet_stable.mp4'\n",
    "\n",
    "def cvt_img2train(img, crop_rate = 1):\n",
    "    img = Image.fromarray(cv2.cvtColor(img,cv2.COLOR_BGR2GRAY))\n",
    "    if (crop_rate != 1):\n",
    "        h = int(height / crop_rate)\n",
    "        dh = int((h - height) / 2)\n",
    "        w = int(width / crop_rate)\n",
    "        dw = int((w - width) / 2)\n",
    "\n",
    "        img = img.resize((w, h), Image.BILINEAR)\n",
    "        img = img.crop((dw, dh, dw + width, dh + height))\n",
    "    else:\n",
    "        img = img.resize((width, height), Image.BILINEAR)\n",
    "    img = np.array(img)\n",
    "    img = img * (1. / 255) - 0.5\n",
    "    img = img.reshape((1, height, width, 1))\n",
    "    return img\n",
    "\n",
    "def make_dirs(path):\n",
    "    if not os.path.exists(path): os.makedirs(path)\n",
    "\n",
    "cvt_train2img = lambda x: ((np.reshape(x, (height, width)) + 0.5) * 255).astype(np.uint8)\n",
    "\n",
    "def warpRevBundle2(img, x_map, y_map):\n",
    "    assert(img.ndim == 3)\n",
    "    assert(img.shape[-1] == 3)\n",
    "    rate = 4\n",
    "    x_map = cv2.resize(cv2.resize(x_map, (int(width / rate), int(height / rate))), (width, height))\n",
    "    y_map = cv2.resize(cv2.resize(y_map, (int(width / rate), int(height / rate))), (width, height))\n",
    "    x_map = (x_map + 1) / 2 * width\n",
    "    y_map = (y_map + 1) / 2 * height\n",
    "    dst = cv2.remap(img, x_map, y_map, cv2.INTER_LINEAR)\n",
    "    assert(dst.shape == (height, width, 3))\n",
    "    return dst\n",
    "\n",
    "production_dir = args.OutputBasePath\n",
    "make_dirs(production_dir)\n",
    "\n",
    "image_len = len([ele for ele in os.listdir(args.InputBasePath) if ele[-4:] == '.jpg'])\n",
    "images = []\n",
    "\n",
    "for i in range(image_len):\n",
    "\n",
    "    #print(os.path.join(args.InputBasePath, '{:03d}.jpg'.format(i)))\n",
    "    \n",
    "    image = cv2.imread(os.path.join(args.InputBasePath, '{:03d}.jpg'.format(i)))\n",
    "    image = cv2.resize(image, (width, height))\n",
    "    images.append(image)\n",
    "\n",
    "print('inference with {}'.format(args.indices))\n",
    "\n",
    "tot_time = 0\n",
    "\n",
    "print('totally {} frames for stabilization'.format(len(images)))\n",
    "\n",
    "before_frames = []\n",
    "before_masks = []\n",
    "after_frames = []\n",
    "after_temp = []\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "frame = images[cnt]\n",
    "\n",
    "cnt += 1\n",
    "\n",
    "for i in range(before_ch):\n",
    "    before_frames.append(cvt_img2train(frame, crop_rate))\n",
    "    before_masks.append(np.zeros([1, height, width, 1], dtype=np.float))\n",
    "    temp = before_frames[i]\n",
    "    temp = ((np.reshape(temp, (height, width)) + 0.5) * 255).astype(np.uint8)\n",
    "\n",
    "    temp = np.concatenate([temp, np.zeros_like(temp)], axis=1)\n",
    "    temp = np.concatenate([temp, np.zeros_like(temp)], axis=0)\n",
    "\n",
    "\n",
    "for i in range(after_ch):\n",
    "    frame = images[cnt]\n",
    "    cnt = cnt + 1\n",
    "    frame_unstable = frame\n",
    "    after_temp.append(frame)\n",
    "    after_frames.append(cvt_img2train(frame, 1))\n",
    "\n",
    "length = 0\n",
    "in_xs = []\n",
    "delta = 0\n",
    "\n",
    "dh = int(height * 0.8 / 2)\n",
    "dw = int(width * 0.8 / 2)\n",
    "all_black = np.zeros([height, width], dtype=np.int64)\n",
    "frames = []\n",
    "\n",
    "black_mask = np.zeros([dh, width], dtype=np.float)\n",
    "temp_mask = np.concatenate([np.zeros([height - 2 * dh, dw], dtype=np.float), np.ones([height - 2 * dh, width - 2 * dw], dtype=np.float), np.zeros([height - 2 * dh, dw], dtype=np.float)], axis=1)\n",
    "black_mask = np.reshape(np.concatenate([black_mask, temp_mask, black_mask], axis=0),[1, height, width, 1]) \n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "\n",
    "        in_x = []\n",
    "        if input_mask:\n",
    "            for i in args.indices:\n",
    "                if (i > 0):\n",
    "                    in_x.append(before_masks[-i])\n",
    "        for i in args.indices:\n",
    "            if (i > 0):\n",
    "                in_x.append(before_frames[-i])\n",
    "        in_x.append(after_frames[0])\n",
    "        for i in args.indices:\n",
    "            if (i < 0):\n",
    "                in_x.append(after_frames[-i])\n",
    "        if (args.no_bm == 0):\n",
    "            in_x.append(black_mask)\n",
    "        # for i in range(after_ch + 1):\n",
    "        in_x = np.concatenate(in_x, axis = 3)\n",
    "        # for max span\n",
    "        if MaxSpan != 1:\n",
    "            in_xs.append(in_x)\n",
    "            if len(in_xs) > MaxSpan: \n",
    "                in_xs = in_xs[-1:]\n",
    "                print('cut')\n",
    "            in_x = in_xs[0].copy()\n",
    "            in_x[0, ..., before_ch] = after_frames[0][..., 0]\n",
    "        tmp_in_x = np.array(in_x.copy())\n",
    "        for j in range(args.refine):\n",
    "            start = time.time()\n",
    "            img, black, x_map_, y_map_ = model.forward(torch.Tensor(tmp_in_x.transpose((0, 3, 1, 2))).cuda())\n",
    "            img = img.cpu().clone().detach().numpy()\n",
    "            black = black.cpu().clone().detach().numpy()\n",
    "            x_map_ = x_map_.cpu().clone().detach().numpy()\n",
    "            y_map_ = y_map_.cpu().clone().detach().numpy()\n",
    "            tot_time += time.time() - start\n",
    "            black = black[0, :, :]\n",
    "            xmap = x_map_[0, :, :, 0]\n",
    "            ymap = y_map_[0, :, :, 0]\n",
    "            all_black = all_black + np.round(black).astype(np.int64)\n",
    "            img = img[0, :, :, :].reshape(height, width)\n",
    "            frame = img + black * (-1)\n",
    "            frame = frame.reshape(1, height, width, 1)\n",
    "            tmp_in_x[..., -1] = frame[..., 0]\n",
    "        img = ((np.reshape(img + 0.5, (height, width))) * 255).astype(np.uint8)\n",
    "\n",
    "        net_output = img\n",
    "\n",
    "        img_warped = warpRevBundle2(cv2.resize(after_temp[0], (width, height)), xmap, ymap)\n",
    "        frames.append(img_warped)\n",
    "\n",
    "        if cnt + 1 <= len(images):\n",
    "            frame_unstable = images[cnt]\n",
    "            cnt = cnt + 1\n",
    "            ret = True\n",
    "        else:\n",
    "            ret = False  \n",
    "\n",
    "        if (not ret):\n",
    "            break\n",
    "        length = length + 1\n",
    "        if (length % 10 == 0):\n",
    "            print(\"length: \" + str(length))      \n",
    "            print('fps={}'.format(length / tot_time))\n",
    "\n",
    "        before_frames.append(frame)\n",
    "        before_masks.append(black.reshape((1, height, width, 1)))\n",
    "        before_frames.pop(0)\n",
    "        before_masks.pop(0)\n",
    "        after_frames.append(cvt_img2train(frame_unstable, 1))\n",
    "        after_frames.pop(0)\n",
    "        after_temp.append(frame_unstable)\n",
    "        after_temp.pop(0)\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    print('total length={}'.format(length + 2))\n",
    "\n",
    "    black_sum = np.zeros([height + 1, width + 1], dtype=np.int64)\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            black_sum[i + 1][j + 1] = black_sum[i][j + 1] + black_sum[i + 1][j] - black_sum[i][j] + all_black[i][j]\n",
    "    max_s = 0\n",
    "    ans = []\n",
    "    for i in range(0, int(math.floor(height * 0.5)), 10):\n",
    "        print(i)\n",
    "        print(max_s)\n",
    "        for j in range(0, int(math.floor(width * 0.5)), 10):\n",
    "            if (all_black[i][j] > 0):\n",
    "                continue\n",
    "            for hh in range(i, height):\n",
    "                dw = int(math.floor(float(max_s) / (hh - i + 1)))\n",
    "                for ww in range(j, width):\n",
    "                    if (black_sum[hh + 1][ww + 1] - black_sum[hh + 1][j] - black_sum[i][ww + 1] + black_sum[i][j] > 0):\n",
    "                        break\n",
    "                    else:\n",
    "                        s = (hh - i + 1) * (ww - j + 1)\n",
    "                        if (s > max_s):\n",
    "                            max_s = s\n",
    "                            ans = [i, j, hh, ww]\n",
    "    videoWriter = cv2.VideoWriter(os.path.join(production_dir, tmp_stable_video_filename), \n",
    "        cv2.VideoWriter_fourcc(*'MP4V'), 25, (ans[3] - ans[1] + 1, ans[2] - ans[0] + 1))\n",
    "    for frame in frames:\n",
    "        frame_ = frame[ans[0]:ans[2] + 1, ans[1]:ans[3] + 1, :]\n",
    "        height, width, channels = frame_.shape\n",
    "        videoWriter.write(frame_)\n",
    "    videoWriter.release()\n",
    "\n",
    "print(\"Frame shape:\",height, width, channels)\n",
    "full_stable_video_filename = os.path.join(production_dir, stable_video_filename)\n",
    "full_tmp_stable_video_filename = os.path.join(production_dir, tmp_stable_video_filename)\n",
    "\n",
    "# OpenCV doesn't ship with the H264 codec that you need to see the video in a notebook; due to licensing incompatabilities. For that reason \n",
    "# I encode as MP4V and then I post process with FFMPEG\n",
    "if os.path.exists(full_stable_video_filename):\n",
    "    os.remove(full_stable_video_filename)\n",
    "    \n",
    "!ffmpeg-4.4-amd64-static/ffmpeg -i {full_tmp_stable_video_filename} -c:v h264 {full_stable_video_filename}\n",
    "    \n",
    "if os.path.exists(full_tmp_stable_video_filename):\n",
    "    os.remove(full_tmp_stable_video_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 360\n",
      "Complete\n",
      "ffmpeg version 4.4-static https://johnvansickle.com/ffmpeg/  Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 8 (Debian 8.3.0-6)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-debug --disable-ffplay --disable-indev=sndio --disable-outdev=sndio --cc=gcc --enable-fontconfig --enable-frei0r --enable-gnutls --enable-gmp --enable-libgme --enable-gray --enable-libaom --enable-libfribidi --enable-libass --enable-libvmaf --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librubberband --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libvorbis --enable-libopus --enable-libtheora --enable-libvidstab --enable-libvo-amrwbenc --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libdav1d --enable-libxvid --enable-libzvbi --enable-libzimg\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'tmp_unstable.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf58.12.100\n",
      "  Duration: 00:00:19.20, start: 0.000000, bitrate: 2312 kb/s\n",
      "  Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 640x360 [SAR 1:1 DAR 16:9], 2311 kb/s, 25 fps, 25 tbr, 12800 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0mprofile High, level 3.0, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0m264 - core 161 r3048 b86ae3c - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=6 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'unstable.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 640x360 [SAR 1:1 DAR 16:9], q=2-31, 25 fps, 12800 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  480 fps=117 q=-1.0 Lsize=    1918kB time=00:00:19.08 bitrate= 823.3kbits/s speed=4.65x    \n",
      "video:1913kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.227899%\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0mframe I:2     Avg QP:21.86  size: 19440\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0mframe P:374   Avg QP:24.40  size:  4757\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0mframe B:104   Avg QP:27.88  size:  1352\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0mconsecutive B-frames: 64.4% 16.7% 10.6%  8.3%\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0mmb I  I16..4:  8.1% 77.0% 14.9%\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0mmb P  I16..4:  1.7%  8.0%  0.5%  P16..4: 51.1% 12.8%  8.4%  0.0%  0.0%    skip:17.4%\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0mmb B  I16..4:  0.4%  1.6%  0.0%  B16..8: 49.3%  4.6%  0.7%  direct: 0.7%  skip:42.6%  L0:53.6% L1:29.9% BI:16.6%\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0m8x8 transform intra:78.4% inter:71.3%\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0mcoded y,uvDC,uvAC intra: 58.6% 41.8% 7.2% inter: 22.9% 16.7% 1.0%\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0mi16 v,h,dc,p: 15% 56% 21%  8%\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 13% 47% 32%  2%  1%  1%  2%  1%  2%\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 20% 37% 16%  4%  5%  5%  5%  5%  5%\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0mi8c dc,h,v,p: 55% 29% 14%  2%\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0mref P L0: 77.4% 13.7%  6.9%  2.0%\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0mref B L0: 89.4%  9.8%  0.8%\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0mref B L1: 99.1%  0.9%\n",
      "\u001b[1;36m[libx264 @ 0x76bea80] \u001b[0mkb/s:816.05\n",
      "ffmpeg version 4.4-static https://johnvansickle.com/ffmpeg/  Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 8 (Debian 8.3.0-6)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-debug --disable-ffplay --disable-indev=sndio --disable-outdev=sndio --cc=gcc --enable-fontconfig --enable-frei0r --enable-gnutls --enable-gmp --enable-libgme --enable-gray --enable-libaom --enable-libfribidi --enable-libass --enable-libvmaf --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librubberband --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libvorbis --enable-libopus --enable-libtheora --enable-libvidstab --enable-libvo-amrwbenc --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libdav1d --enable-libxvid --enable-libzvbi --enable-libzimg\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'tmp_clipped_unstable.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf58.12.100\n",
      "  Duration: 00:00:19.20, start: 0.000000, bitrate: 986 kb/s\n",
      "  Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 342x206 [SAR 1:1 DAR 171:103], 985 kb/s, 25 fps, 25 tbr, 12800 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0mprofile High, level 1.3, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0m264 - core 161 r3048 b86ae3c - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=6 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'clipped_unstable.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 342x206 [SAR 1:1 DAR 171:103], q=2-31, 25 fps, 12800 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  480 fps=334 q=-1.0 Lsize=     633kB time=00:00:19.08 bitrate= 271.9kbits/s speed=13.3x    \n",
      "video:628kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.857531%\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0mframe I:2     Avg QP:23.52  size:  6248\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0mframe P:280   Avg QP:24.96  size:  1818\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0mframe B:198   Avg QP:28.44  size:   609\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0mconsecutive B-frames: 36.2% 20.8% 16.2% 26.7%\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0mmb I  I16..4:  7.7% 71.0% 21.3%\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0mmb P  I16..4:  2.2%  8.0%  1.6%  P16..4: 47.5% 14.8%  8.3%  0.0%  0.0%    skip:17.5%\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0mmb B  I16..4:  0.7%  1.7%  0.2%  B16..8: 45.5%  6.9%  1.8%  direct: 1.4%  skip:41.9%  L0:46.2% L1:42.5% BI:11.2%\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0m8x8 transform intra:67.3% inter:71.0%\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0mcoded y,uvDC,uvAC intra: 58.0% 45.6% 11.8% inter: 19.5% 14.9% 1.1%\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0mi16 v,h,dc,p:  9% 66% 17%  7%\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu:  8% 56% 25%  1%  1%  1%  3%  1%  3%\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 14% 46% 14%  3%  5%  5%  5%  4%  4%\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0mi8c dc,h,v,p: 54% 33% 11%  2%\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0mref P L0: 75.5% 13.1%  8.5%  2.9%\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0mref B L0: 91.4%  7.6%  1.0%\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0mref B L1: 98.3%  1.7%\n",
      "\u001b[1;36m[libx264 @ 0x64c04c0] \u001b[0mkb/s:267.58\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "image_folder = 'DUTCode/images'\n",
    "tmp_video_name = 'tmp_unstable.mp4'\n",
    "video_name = 'unstable.mp4'\n",
    "tmp_clipped_video_name = 'tmp_clipped_unstable.mp4'\n",
    "clipped_video_name = 'clipped_unstable.mp4'\n",
    "\n",
    "height = 0\n",
    "width = 0\n",
    "total_number = 480\n",
    "    \n",
    "for img in os.listdir(image_folder):\n",
    "    file, ext = os.path.splitext(img)\n",
    "    if img.endswith(\".jpg\"):\n",
    "        file_name_corrected = os.path.join(image_folder,file.zfill(3)+'.jpg')\n",
    "        uncorrected_file_name =  os.path.join(image_folder,img)\n",
    "        #print(uncorrected_file_name +' => ' + file_name_corrected)\n",
    "        os.rename(uncorrected_file_name,file_name_corrected)\n",
    "        \n",
    "        frame = cv2.imread(file_name_corrected)\n",
    "        height, width, channels = frame.shape\n",
    "\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "print(width, height)\n",
    "\n",
    "video = cv2.VideoWriter(tmp_video_name, fourcc, 25, (width, height))\n",
    "\n",
    "# Now that everything is renamed it should be in the correct order\n",
    "for img_number in range(480):\n",
    "    image = os.path.join(image_folder,str(img_number).zfill(3)+'.jpg')\n",
    "    #print(image)\n",
    "    img = cv2.imread(image)\n",
    "    \n",
    "    video.write(img)\n",
    "\n",
    "video.release()\n",
    "\n",
    "\n",
    "clipped_video = cv2.VideoWriter(tmp_clipped_video_name, fourcc, 25, (342, 206))\n",
    "\n",
    "# Now that everything is renamed it should be in the correct order\n",
    "for img_number in range(480):\n",
    "    image = os.path.join(image_folder,str(img_number).zfill(3)+'.jpg')\n",
    "    #print(image)\n",
    "    img = cv2.imread(image)\n",
    "\n",
    "    y_offset = (height-206)//2\n",
    "    x_offset = (width-342)//2\n",
    "    crop_img = img[y_offset:y_offset+206, x_offset:x_offset+342]\n",
    "    #print(crop_img.shape)\n",
    "    clipped_video.write(crop_img)\n",
    "\n",
    "clipped_video.release()\n",
    "\n",
    "print('Complete')\n",
    "\n",
    "# OpenCV doesn't ship with the H264 codec that you need to see the video in a notebook; due to licensing incompatabilities. For that reason \n",
    "# I encode as MP4V and then I post process with FFMPEG\n",
    "if os.path.exists(video_name):\n",
    "    os.remove(video_name)\n",
    "if os.path.exists(clipped_video_name):\n",
    "    os.remove(clipped_video_name)\n",
    "\n",
    "!ffmpeg-4.4-amd64-static/ffmpeg -i {tmp_video_name} -c:v h264 {video_name}\n",
    "!ffmpeg-4.4-amd64-static/ffmpeg -i {tmp_clipped_video_name} -c:v h264 {clipped_video_name}\n",
    "    \n",
    "if os.path.exists(tmp_video_name):\n",
    "    os.remove(tmp_video_name)\n",
    "if os.path.exists(tmp_clipped_video_name):\n",
    "    os.remove(tmp_clipped_video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center>Full Unstable (640x360)</center>\n",
       "<video width=\"640\" height=\"360\" controls autoplay>\n",
       "    <source src=\"unstable.mp4\" type=\"video/mp4\">\n",
       "</video>\n",
       "\n",
       "<table>\n",
       "  <tr>\n",
       "    <td>\n",
       "        <center>Clipped Unstabalized (342x206)</center>\n",
       "        <video width=\"342\" height=\"206\" controls autoplay>\n",
       "          <source src=\"clipped_unstable.mp4\" type=\"video/mp4\">\n",
       "        </video>\n",
       "    </td>\n",
       "    <td>\n",
       "        <center>Stabalized (342x206)</center>\n",
       "        <video width=\"342\" height=\"206\" controls autoplay>\n",
       "          <source src=\"results/StabNet_stable.mp4\" type=\"video/mp4\">\n",
       "        </video>\n",
       "    </td>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<center>Full Unstable (640x360)</center>\n",
    "<video width=\"640\" height=\"360\" controls autoplay>\n",
    "    <source src=\"unstable.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>\n",
    "        <center>Clipped Unstabalized (342x206)</center>\n",
    "        <video width=\"342\" height=\"206\" controls autoplay>\n",
    "          <source src=\"clipped_unstable.mp4\" type=\"video/mp4\">\n",
    "        </video>\n",
    "    </td>\n",
    "    <td>\n",
    "        <center>Stabalized (342x206)</center>\n",
    "        <video width=\"342\" height=\"206\" controls autoplay>\n",
    "          <source src=\"results/StabNet_stable.mp4\" type=\"video/mp4\">\n",
    "        </video>\n",
    "    </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running DUT Stabalizer\n",
    "\n",
    "These are the interesting pieces:\n",
    "\n",
    "```bash\n",
    "OutputBasePath='results/'\n",
    "SmootherPath='ckpt/smoother.pth'\n",
    "RFDetPath='ckpt/RFDet_640.pth.tar'\n",
    "PWCNetPath='ckpt/network-default.pytorch'\n",
    "MotionProPath='ckpt/MotionPro.pth'\n",
    "InputPath='images/'\n",
    "```\n",
    "\n",
    "```bash\n",
    "# Run the DUT model\n",
    "echo \" Stabiling using the DUT model \"\n",
    "echo \"-----------------------------------\"\n",
    "\n",
    "python ./scripts/DUTStabilizer.py \\\n",
    "\t--SmootherPath=$SmootherPath \\\n",
    "    --RFDetPath=$RFDetPath \\\n",
    "    --PWCNetPath=$PWCNetPath \\\n",
    "    --MotionPro=$MotionProPath \\\n",
    "    --InputBasePath=$InputPath \\\n",
    "    --OutputBasePath=$OutputBasePath \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So given this I will pull the code from StabNetStabilizer.py to explore it. I will modify it as needed to support running from the notebook so I can really get in and explore what is going on.\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import cv2\n",
    "import sys\n",
    "parentddir = os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir))\n",
    "sys.path.append(parentddir)\n",
    "\n",
    "from models.DUT.DUT import DUT\n",
    "from tqdm import tqdm\n",
    "from utils.WarpUtils import warpListImage\n",
    "from configs.config import cfg\n",
    "import argparse\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Control for stabilization model')\n",
    "    parser.add_argument('--SmootherPath', help='the path to pretrained smoother model, blank for jacobi solver', default='')\n",
    "    parser.add_argument('--RFDetPath', help='pretrained RFNet path, blank for corner detection', default='')\n",
    "    parser.add_argument('--PWCNetPath', help='pretrained pwcnet path, blank for KTL tracker', default='')\n",
    "    parser.add_argument('--MotionProPath', help='pretrained motion propagation model path, blank for median', default='')\n",
    "    parser.add_argument('--SingleHomo', help='whether use multi homograph to do motion estimation', action='store_true')\n",
    "    parser.add_argument('--InputBasePath', help='path to input videos (cliped as frames)', default='')\n",
    "    parser.add_argument('--OutputBasePath', help='path to save output stable videos', default='./')\n",
    "    parser.add_argument('--OutNamePrefix', help='prefix name before the output video name', default='')\n",
    "    parser.add_argument('--MaxLength', help='max number of frames can be dealt with one time', type=int, default=1200)\n",
    "    parser.add_argument('--Repeat', help='max number of frames can be dealt with one time', type=int, default=50)\n",
    "    return parser.parse_args()\n",
    "\n",
    "def generateStable(model, base_path, outPath, outPrefix, max_length, args):\n",
    "\n",
    "    image_base_path = base_path\n",
    "    image_len = min(len([ele for ele in os.listdir(image_base_path) if ele[-4:] == '.jpg']), max_length)\n",
    "    # read input video\n",
    "    images = []\n",
    "    rgbimages = []\n",
    "    for i in range(image_len):\n",
    "        image = cv2.imread(os.path.join(image_base_path, '{}.jpg'.format(i)), 0)\n",
    "        image = image * (1. / 255.)\n",
    "        image = cv2.resize(image, (cfg.MODEL.WIDTH, cfg.MODEL.HEIGHT))\n",
    "        images.append(image.reshape(1, 1, cfg.MODEL.HEIGHT, cfg.MODEL.WIDTH))\n",
    "\n",
    "        image = cv2.imread(os.path.join(image_base_path, '{}.jpg'.format(i)))\n",
    "        image = cv2.resize(image, (cfg.MODEL.WIDTH, cfg.MODEL.HEIGHT))\n",
    "        rgbimages.append(np.expand_dims(np.transpose(image, (2, 0, 1)), 0))\n",
    "\n",
    "    x = np.concatenate(images, 1).astype(np.float32)\n",
    "    x = torch.from_numpy(x).unsqueeze(0)\n",
    "\n",
    "    x_RGB = np.concatenate(rgbimages, 0).astype(np.float32)\n",
    "    x_RGB = torch.from_numpy(x_RGB).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        origin_motion, smoothPath = model.inference(x.cuda(), x_RGB.cuda(), repeat=args.Repeat)\n",
    "\n",
    "    origin_motion = origin_motion.cpu().numpy()\n",
    "    smoothPath = smoothPath.cpu().numpy()\n",
    "    origin_motion = np.transpose(origin_motion[0], (2, 3, 1, 0))\n",
    "    smoothPath = np.transpose(smoothPath[0], (2, 3, 1, 0))\n",
    "\n",
    "    x_paths = origin_motion[:, :, :, 0]\n",
    "    y_paths = origin_motion[:, :, :, 1]\n",
    "    sx_paths = smoothPath[:, :, :, 0]\n",
    "    sy_paths = smoothPath[:, :, :, 1]\n",
    "\n",
    "    frame_rate = 25\n",
    "    frame_width = cfg.MODEL.WIDTH\n",
    "    frame_height = cfg.MODEL.HEIGHT\n",
    "    \n",
    "    print(\"generate stabilized video...\")\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    out = cv2.VideoWriter(os.path.join(outPath, outPrefix + 'DUT_stable.mp4'), fourcc, frame_rate, (frame_width, frame_height))\n",
    "\n",
    "    new_x_motion_meshes = sx_paths - x_paths\n",
    "    new_y_motion_meshes = sy_paths - y_paths\n",
    "\n",
    "    outImages = warpListImage(rgbimages, new_x_motion_meshes, new_y_motion_meshes)\n",
    "    outImages = outImages.numpy().astype(np.uint8)\n",
    "    outImages = [np.transpose(outImages[idx], (1, 2, 0)) for idx in range(outImages.shape[0])]\n",
    "    for frame in tqdm(outImages):\n",
    "        VERTICAL_BORDER = 60\n",
    "        HORIZONTAL_BORDER = 80\n",
    "\n",
    "        new_frame = frame[VERTICAL_BORDER:-VERTICAL_BORDER, HORIZONTAL_BORDER:-HORIZONTAL_BORDER]\n",
    "        new_frame = cv2.resize(new_frame, (frame.shape[1], frame.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
    "        out.write(new_frame)\n",
    "    out.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    args = parse_args()\n",
    "    print(args)\n",
    "\n",
    "    smootherPath = args.SmootherPath\n",
    "    RFDetPath = args.RFDetPath\n",
    "    PWCNetPath = args.PWCNetPath\n",
    "    MotionProPath = args.MotionProPath\n",
    "    homo = not args.SingleHomo\n",
    "    inPath = args.InputBasePath\n",
    "    outPath = args.OutputBasePath\n",
    "    outPrefix = args.OutNamePrefix\n",
    "    maxlength = args.MaxLength\n",
    "\n",
    "    model = DUT(SmootherPath=smootherPath, RFDetPath=RFDetPath, PWCNetPath=PWCNetPath, MotionProPath=MotionProPath, homo=homo)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    generateStable(model, inPath, outPath, outPrefix, maxlength, args)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From deploy_samples.sh\n",
    "\n",
    "#OutputBasePath='results/'\n",
    "#SmootherPath='ckpt/smoother.pth'\n",
    "#RFDetPath='ckpt/RFDet_640.pth.tar'\n",
    "#PWCNetPath='ckpt/network-default.pytorch'\n",
    "#MotionProPath='ckpt/MotionPro.pth'\n",
    "#InputPath='images/'\n",
    "\n",
    "#--SmootherPath=$SmootherPath \\\n",
    "#--RFDetPath=$RFDetPath \\\n",
    "#--PWCNetPath=$PWCNetPath \\\n",
    "#--MotionPro=$MotionProPath \\\n",
    "#--InputBasePath=$InputPath \\\n",
    "#--OutputBasePath=$OutputBasePath \n",
    "class DUTArguments:\n",
    "    \n",
    "    SmootherPath='DUTPretrained/ckpt/smoother.pth'\n",
    "    RFDetPath='DUTPretrained/ckpt/RFDet_640.pth.tar'\n",
    "    PWCNetPath='DUTPretrained/ckpt/network-default.pytorch'\n",
    "    MotionProPath='DUTPretrained/ckpt/MotionPro.pth'\n",
    "    SingleHomo=True\n",
    "    OutputBasePath = 'results/'\n",
    "    InputBasePath = 'DUTCode/images/'\n",
    "    MaxLength = 1200\n",
    "    OutNamePrefix = ''\n",
    "    Repeat = 50\n",
    "    \n",
    "dut_args = DUTArguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateStable(model, base_path, outPath, outPrefix, max_length, args):\n",
    "\n",
    "    image_base_path = base_path\n",
    "    image_len = min(len([ele for ele in os.listdir(image_base_path) if ele[-4:] == '.jpg']), max_length)\n",
    "    # read input video\n",
    "    images = []\n",
    "    rgbimages = []\n",
    "    for i in range(image_len):\n",
    "        image = cv2.imread(os.path.join(args.InputBasePath, '{:03d}.jpg'.format(i)), 0)\n",
    "        image = image * (1. / 255.)\n",
    "        image = cv2.resize(image, (cfg.MODEL.WIDTH, cfg.MODEL.HEIGHT))\n",
    "        images.append(image.reshape(1, 1, cfg.MODEL.HEIGHT, cfg.MODEL.WIDTH))\n",
    "\n",
    "        image = cv2.imread(os.path.join(args.InputBasePath, '{:03d}.jpg'.format(i)))\n",
    "        image = cv2.resize(image, (cfg.MODEL.WIDTH, cfg.MODEL.HEIGHT))\n",
    "        rgbimages.append(np.expand_dims(np.transpose(image, (2, 0, 1)), 0))\n",
    "\n",
    "    x = np.concatenate(images, 1).astype(np.float32)\n",
    "    x = torch.from_numpy(x).unsqueeze(0)\n",
    "\n",
    "    x_RGB = np.concatenate(rgbimages, 0).astype(np.float32)\n",
    "    x_RGB = torch.from_numpy(x_RGB).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        origin_motion, smoothPath = model.inference(x.cuda(), x_RGB.cuda(), repeat=args.Repeat)\n",
    "\n",
    "    origin_motion = origin_motion.cpu().numpy()\n",
    "    smoothPath = smoothPath.cpu().numpy()\n",
    "    origin_motion = np.transpose(origin_motion[0], (2, 3, 1, 0))\n",
    "    smoothPath = np.transpose(smoothPath[0], (2, 3, 1, 0))\n",
    "\n",
    "    x_paths = origin_motion[:, :, :, 0]\n",
    "    y_paths = origin_motion[:, :, :, 1]\n",
    "    sx_paths = smoothPath[:, :, :, 0]\n",
    "    sy_paths = smoothPath[:, :, :, 1]\n",
    "\n",
    "    frame_rate = 25\n",
    "    frame_width = cfg.MODEL.WIDTH\n",
    "    frame_height = cfg.MODEL.HEIGHT\n",
    "\n",
    "    print(\"generate stabilized video...\")\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    out = cv2.VideoWriter(os.path.join(outPath, outPrefix + 'tmp_DUT_stable.mp4'), fourcc, frame_rate, (frame_width, frame_height))\n",
    "    print(frame_width, frame_height)\n",
    "\n",
    "    new_x_motion_meshes = sx_paths - x_paths\n",
    "    new_y_motion_meshes = sy_paths - y_paths\n",
    "\n",
    "    outImages = warpListImage(rgbimages, new_x_motion_meshes, new_y_motion_meshes)\n",
    "    outImages = outImages.numpy().astype(np.uint8)\n",
    "    outImages = [np.transpose(outImages[idx], (1, 2, 0)) for idx in range(outImages.shape[0])]\n",
    "    for frame in tqdm(outImages):\n",
    "        VERTICAL_BORDER = 60\n",
    "        HORIZONTAL_BORDER = 80\n",
    "\n",
    "        new_frame = frame[VERTICAL_BORDER:-VERTICAL_BORDER, HORIZONTAL_BORDER:-HORIZONTAL_BORDER]\n",
    "        new_frame = cv2.resize(new_frame, (frame.shape[1], frame.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
    "        #print(new_frame.shape)\n",
    "        out.write(new_frame)\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------model configuration------------------------\n",
      "using RFNet ...\n",
      "using PWCNet for motion estimation...\n",
      "using Motion Propagation model with multi homo...\n",
      "using Deep Smoother Model...\n",
      "------------------reload parameters-------------------------\n",
      "reload Smoother params\n",
      "successfully load 12 params for smoother\n",
      "reload RFDet Model\n",
      "successfully load 100 params for RFDet\n",
      "reload PWCNet Model\n",
      "reload MotionPropagation Model\n",
      "successfully load 21 params for MotionPropagation\n",
      "detect keypoints ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/hand-tracking-stabilization/DUTCode/models/DUT/rf_det_module.py:202: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  None, None, :, :\n",
      "/root/hand-tracking-stabilization/DUTCode/models/DUT/DUT.py:92: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /codebuild/output/src811146734/src/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  kpts = im_topk.nonzero()  # (B*topk, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate motion ....\n",
      "motion propagation ....\n",
      "generate stabilized video...\n",
      "640 480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 480/480 [00:02<00:00, 221.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4-static https://johnvansickle.com/ffmpeg/  Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 8 (Debian 8.3.0-6)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-debug --disable-ffplay --disable-indev=sndio --disable-outdev=sndio --cc=gcc --enable-fontconfig --enable-frei0r --enable-gnutls --enable-gmp --enable-libgme --enable-gray --enable-libaom --enable-libfribidi --enable-libass --enable-libvmaf --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librubberband --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libvorbis --enable-libopus --enable-libtheora --enable-libvidstab --enable-libvo-amrwbenc --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libdav1d --enable-libxvid --enable-libzvbi --enable-libzimg\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'results/tmp_DUT_stable.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf58.12.100\n",
      "  Duration: 00:00:19.20, start: 0.000000, bitrate: 2032 kb/s\n",
      "  Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 640x480 [SAR 1:1 DAR 4:3], 2030 kb/s, 25 fps, 25 tbr, 12800 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0mprofile High, level 3.0, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0m264 - core 161 r3048 b86ae3c - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=6 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'results/DUT_stable.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 640x480 [SAR 1:1 DAR 4:3], q=2-31, 25 fps, 12800 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  480 fps= 94 q=-1.0 Lsize=    1918kB time=00:00:19.08 bitrate= 823.7kbits/s speed=3.72x    \n",
      "video:1914kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.233487%\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0mframe I:2     Avg QP:21.91  size: 15254\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0mframe P:347   Avg QP:23.95  size:  4865\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0mframe B:131   Avg QP:27.12  size:  1836\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0mconsecutive B-frames: 59.2% 10.0% 10.0% 20.8%\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0mmb I  I16..4: 13.6% 80.0%  6.4%\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0mmb P  I16..4:  2.1%  8.4%  0.3%  P16..4: 53.1% 11.8%  5.6%  0.0%  0.0%    skip:18.6%\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0mmb B  I16..4:  0.8%  3.2%  0.0%  B16..8: 44.2%  4.2%  0.6%  direct: 0.9%  skip:46.2%  L0:52.6% L1:40.0% BI: 7.4%\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0m8x8 transform intra:78.0% inter:82.0%\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0mcoded y,uvDC,uvAC intra: 49.7% 43.2% 9.0% inter: 19.9% 17.1% 0.7%\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0mi16 v,h,dc,p: 16% 52% 20% 12%\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 14% 41% 36%  1%  1%  1%  2%  1%  2%\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25% 26% 15%  4%  7%  8%  6%  6%  4%\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0mi8c dc,h,v,p: 56% 27% 16%  2%\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0mref P L0: 77.3% 11.6%  8.8%  2.3%\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0mref B L0: 91.9%  7.2%  0.9%\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0mref B L1: 98.2%  1.8%\n",
      "\u001b[1;36m[libx264 @ 0x7018dc0] \u001b[0mkb/s:816.32\n"
     ]
    }
   ],
   "source": [
    "from models.DUT.DUT import DUT\n",
    "from utils.WarpUtils import warpListImage\n",
    "from configs.config import cfg\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = DUT(SmootherPath=dut_args.SmootherPath, RFDetPath=dut_args.RFDetPath, PWCNetPath=dut_args.PWCNetPath, MotionProPath=dut_args.MotionProPath, homo=dut_args.SingleHomo)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "generateStable(model, dut_args.InputBasePath, dut_args.OutputBasePath, dut_args.OutNamePrefix, dut_args.MaxLength, dut_args)\n",
    "\n",
    "# OpenCV doesn't ship with the H264 codec that you need to see the video in a notebook; due to licensing incompatabilities. For that reason \n",
    "# I encode as MP4V and then I post process with FFMPEG\n",
    "video_name =os.path.join(dut_args.OutputBasePath,'DUT_stable.mp4')\n",
    "tmp_video_name = os.path.join(dut_args.OutputBasePath,'tmp_DUT_stable.mp4')\n",
    "\n",
    "if os.path.exists(video_name):\n",
    "    os.remove(video_name)\n",
    "\n",
    "!ffmpeg-4.4-amd64-static/ffmpeg -i {tmp_video_name} -c:v h264 {video_name}\n",
    "    \n",
    "if os.path.exists(tmp_video_name):\n",
    "    os.remove(tmp_video_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table>\n",
       "  <tr>\n",
       "    <td>\n",
       "        <center>Full Unstable (640x360)</center>\n",
       "        <video width=\"640\" height=\"360\" controls autoplay>\n",
       "            <source src=\"unstable.mp4\" type=\"video/mp4\">\n",
       "        </video>\n",
       "    </td>\n",
       "  <tr>\n",
       "    <td>\n",
       "        <center>Stabalized (640x480)</center>\n",
       "        <video width=\"640\" height=\"480\" controls autoplay>\n",
       "          <source src=\"results/DUT_stable.mp4\" type=\"video/mp4\">\n",
       "        </video>\n",
       "    </td>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>\n",
    "        <center>Full Unstable (640x360)</center>\n",
    "        <video width=\"640\" height=\"360\" controls autoplay>\n",
    "            <source src=\"unstable.mp4\" type=\"video/mp4\">\n",
    "        </video>\n",
    "    </td>\n",
    "  <tr>\n",
    "    <td>\n",
    "        <center>Stabalized (640x480)</center>\n",
    "        <video width=\"640\" height=\"480\" controls autoplay>\n",
    "          <source src=\"results/DUT_stable.mp4\" type=\"video/mp4\">\n",
    "        </video>\n",
    "    </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running DIFRINT  Stabalizer\n",
    "\n",
    "These are the interesting pieces:\n",
    "\n",
    "```bash\n",
    "modelPath=='DUTPretrained/ckpt/DIFNet2.pth'\n",
    "InputBasePath='images/'\n",
    "OutputBasePath='results/'\n",
    "```\n",
    "\n",
    "```bash\n",
    "# Run the DIFRINT model\n",
    "echo \" Stabiling using the DIFRINT model \"\n",
    "echo \"-----------------------------------\"\n",
    "\n",
    "python ./scripts/DIFRINTStabilizer.py \\\n",
    "    --modelPath=$DIFPath \\\n",
    "    --InputBasePath=$InputPath \\\n",
    "    --OutputBasePath=$OutputBasePath \\\n",
    "    --cuda \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So given this I will pull the code from DIFRINTStabilizer.py to explore it. I will modify it as needed to support running from the notebook so I can really get in and explore what is going on.\n",
    "\n",
    "```python\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from shutil import copyfile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "parentddir = os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir))\n",
    "sys.path.append(parentddir)\n",
    "from models.DIFRINT.models import DIFNet2\n",
    "from models.DIFRINT.pwcNet import PwcNet\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "import pdb\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--modelPath', default='./trained_models/DIFNet2.pth')  # 2\n",
    "parser.add_argument('--InputBasePath', default='')\n",
    "parser.add_argument('--OutputBasePath', default='./')\n",
    "parser.add_argument('--temp_file', default='./DIFRINT_TEMP/')\n",
    "parser.add_argument('--n_iter', type=int, default=3,\n",
    "                    help='number of stabilization interations')\n",
    "parser.add_argument('--skip', type=int, default=2,\n",
    "                    help='number of frame skips for interpolation')\n",
    "parser.add_argument('--desiredWidth', type=int, default=640,\n",
    "                    help='width of the input video')\n",
    "parser.add_argument('--desiredHeight', type=int, default=480,\n",
    "                    help='height of the input video')\n",
    "parser.add_argument('--cuda', action='store_true', help='use GPU computation')\n",
    "opt = parser.parse_args()\n",
    "print(opt)\n",
    "\n",
    "if torch.cuda.is_available() and not opt.cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "##########################################################\n",
    "\n",
    "# Networks\n",
    "DIFNet = DIFNet2()\n",
    "\n",
    "# Place Network in cuda memory\n",
    "if opt.cuda:\n",
    "    DIFNet.cuda()\n",
    "\n",
    "# DataParallel\n",
    "DIFNet = nn.DataParallel(DIFNet)\n",
    "DIFNet.load_state_dict(torch.load(opt.modelPath))\n",
    "DIFNet.eval()\n",
    "\n",
    "if not os.path.exists(opt.OutputBasePath):\n",
    "    os.mkdir(opt.OutputBasePath)\n",
    "\n",
    "if not os.path.exists(opt.temp_file):\n",
    "    os.mkdir(opt.temp_file)\n",
    "\n",
    "##########################################################\n",
    "\n",
    "frameList = [ele for ele in os.listdir(opt.InputBasePath) if ele[-4:] == '.jpg']\n",
    "frameList = sorted(frameList, key=lambda x: int(x[:-4]))\n",
    "\n",
    "if os.path.exists(opt.temp_file):\n",
    "    copyfile(opt.InputBasePath + frameList[0], opt.temp_file + frameList[0])\n",
    "    copyfile(opt.InputBasePath + frameList[-1], opt.temp_file + frameList[-1])\n",
    "else:\n",
    "    os.makedirs(opt.temp_file)\n",
    "    copyfile(opt.InputBasePath + frameList[0], opt.temp_file + frameList[0])\n",
    "    copyfile(opt.InputBasePath + frameList[-1], opt.temp_file + frameList[-1])\n",
    "# end\n",
    "\n",
    "# Generate output sequence\n",
    "for num_iter in range(opt.n_iter):\n",
    "    idx = 1\n",
    "    print('\\nIter: ' + str(num_iter+1))\n",
    "    for f in frameList[1:-1]:\n",
    "        if f.endswith('.jpg'):\n",
    "            if num_iter == 0:\n",
    "                src = opt.InputBasePath\n",
    "            else:\n",
    "                src = opt.temp_file\n",
    "            # end\n",
    "\n",
    "            if idx < opt.skip or idx > (len(frameList)-1-opt.skip):\n",
    "                skip = 1\n",
    "            else:\n",
    "                skip = opt.skip\n",
    "\n",
    "\n",
    "            fr_g1 = torch.cuda.FloatTensor(np.array(Image.open(opt.temp_file + '%d.jpg' % (\n",
    "                int(f[:-4])-skip)).resize((opt.desiredWidth, opt.desiredHeight))).transpose(2, 0, 1).astype(np.float32)[None, :, :, :] / 255.0)\n",
    "\n",
    "            fr_g3 = torch.cuda.FloatTensor(np.array(Image.open(\n",
    "                src + '%d.jpg' % (int(f[:-4])+skip)).resize((opt.desiredWidth, opt.desiredHeight))).transpose(2, 0, 1).astype(np.float32)[None, :, :, :] / 255.0)\n",
    "\n",
    "\n",
    "            fr_o2 = torch.cuda.FloatTensor(np.array(Image.open(\n",
    "                opt.InputBasePath + f).resize((opt.desiredWidth, opt.desiredHeight))).transpose(2, 0, 1).astype(np.float32)[None, :, :, :] / 255.0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fhat, I_int = DIFNet(fr_g1, fr_g3, fr_o2,\n",
    "                                     fr_g3, fr_g1, 0.5)  # Notice 0.5\n",
    "\n",
    "            # Save image\n",
    "            img = Image.fromarray(\n",
    "                np.uint8(fhat.cpu().squeeze().permute(1, 2, 0)*255))\n",
    "            img.save(opt.temp_file + f)\n",
    "\n",
    "            sys.stdout.write('\\rFrame: ' + str(idx) +\n",
    "                             '/' + str(len(frameList)-2))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            idx += 1\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "frame_rate = 25\n",
    "frame_width = opt.desiredWidth\n",
    "frame_height = opt.desiredHeight\n",
    "\n",
    "print(\"generate stabilized video...\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter(opt.OutputBasePath + '/DIFRINT_stable.mp4', fourcc, frame_rate, (frame_width, frame_height))\n",
    "\n",
    "for f in frameList:\n",
    "    if f.endswith('.jpg'):\n",
    "        img = cv2.imread(os.path.join(opt.temp_file, f))\n",
    "        out.write(img)\n",
    "\n",
    "out.release()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DIFNetArguments:\n",
    "    \n",
    "    modelPath='DUTPretrained/ckpt/DIFNet2.pth'\n",
    "    InputBasePath='DUTCode/images/'\n",
    "    OutputBasePath='results/'\n",
    "    temp_file='./DUTCode/DIFRINT_TEMP/'\n",
    "    skip= 2\n",
    "    desiredWidth= 640\n",
    "    desiredHeight= 480\n",
    "    n_iter= 3\n",
    "\n",
    "difnet_args = DIFNetArguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.DIFRINT.models import DIFNet2\n",
    "from models.DIFRINT.pwcNet import PwcNet\n",
    "\n",
    "# Networks\n",
    "DIFNet = DIFNet2()\n",
    "DIFNet.cuda()\n",
    "\n",
    "# DataParallel\n",
    "DIFNet = nn.DataParallel(DIFNet)\n",
    "DIFNet.load_state_dict(torch.load(difnet_args.modelPath))\n",
    "DIFNet.eval()\n",
    "\n",
    "if not os.path.exists(difnet_args.OutputBasePath):\n",
    "    os.mkdir(difnet_args.OutputBasePath)\n",
    "\n",
    "if not os.path.exists(difnet_args.temp_file):\n",
    "    os.mkdir(difnet_args.temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iter: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:3384: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame: 478/478\n",
      "Iter: 2\n",
      "Frame: 478/478\n",
      "Iter: 3\n",
      "Frame: 478/478\n",
      "generate stabilized video...\n",
      "ffmpeg version 4.4-static https://johnvansickle.com/ffmpeg/  Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 8 (Debian 8.3.0-6)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-debug --disable-ffplay --disable-indev=sndio --disable-outdev=sndio --cc=gcc --enable-fontconfig --enable-frei0r --enable-gnutls --enable-gmp --enable-libgme --enable-gray --enable-libaom --enable-libfribidi --enable-libass --enable-libvmaf --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librubberband --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libvorbis --enable-libopus --enable-libtheora --enable-libvidstab --enable-libvo-amrwbenc --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libdav1d --enable-libxvid --enable-libzvbi --enable-libzimg\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'results/tmp_DUT_stable.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf58.12.100\n",
      "  Duration: 00:00:19.12, start: 0.000000, bitrate: 3314 kb/s\n",
      "  Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 640x480 [SAR 1:1 DAR 4:3], 3313 kb/s, 25 fps, 25 tbr, 12800 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0mprofile High, level 3.0, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0m264 - core 161 r3048 b86ae3c - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=6 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'results/DIFRINT_stable.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 640x480 [SAR 1:1 DAR 4:3], q=2-31, 25 fps, 12800 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  478 fps= 83 q=-1.0 Lsize=    2606kB time=00:00:19.00 bitrate=1123.7kbits/s speed= 3.3x    \n",
      "video:2601kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.209372%\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0mframe I:2     Avg QP:22.49  size: 20534\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0mframe P:258   Avg QP:24.43  size:  7780\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0mframe B:218   Avg QP:26.99  size:  2818\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0mconsecutive B-frames: 35.6%  8.8%  6.3% 49.4%\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0mmb I  I16..4: 10.8% 83.3%  5.9%\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0mmb P  I16..4:  2.3% 13.5%  0.5%  P16..4: 52.1% 15.9%  7.9%  0.0%  0.0%    skip: 7.8%\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0mmb B  I16..4:  1.2%  6.6%  0.1%  B16..8: 46.1%  6.7%  1.2%  direct: 2.1%  skip:36.2%  L0:47.5% L1:41.1% BI:11.4%\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0m8x8 transform intra:83.0% inter:79.6%\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0mcoded y,uvDC,uvAC intra: 54.8% 51.3% 7.7% inter: 26.0% 27.9% 0.9%\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0mi16 v,h,dc,p: 18% 45% 23% 15%\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 20% 36% 36%  1%  1%  1%  2%  1%  2%\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 24% 27% 15%  4%  6%  8%  5%  6%  5%\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0mi8c dc,h,v,p: 53% 27% 18%  2%\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0mref P L0: 71.2% 16.7%  9.6%  2.5%\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0mref B L0: 93.9%  5.2%  0.9%\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0mref B L1: 98.4%  1.6%\n",
      "\u001b[1;36m[libx264 @ 0x65c1d00] \u001b[0mkb/s:1114.02\n"
     ]
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "frameList = [ele for ele in os.listdir(difnet_args.InputBasePath) if ele[-4:] == '.jpg']\n",
    "frameList = sorted(frameList, key=lambda x: int(x[:-4]))\n",
    "\n",
    "if os.path.exists(difnet_args.temp_file):\n",
    "    copyfile(difnet_args.InputBasePath + frameList[0], difnet_args.temp_file + frameList[0])\n",
    "    copyfile(difnet_args.InputBasePath + frameList[-1], difnet_args.temp_file + frameList[-1])\n",
    "else:\n",
    "    os.makedirs(difnet_args.temp_file)\n",
    "    copyfile(difnet_args.InputBasePath + frameList[0], difnet_args.temp_file + frameList[0])\n",
    "    copyfile(difnet_args.InputBasePath + frameList[-1], difnet_args.temp_file + frameList[-1])\n",
    "# end\n",
    "\n",
    "# Generate output sequence\n",
    "for num_iter in range(difnet_args.n_iter):\n",
    "    idx = 1\n",
    "    print('\\nIter: ' + str(num_iter+1))\n",
    "    for f in frameList[1:-1]:\n",
    "        if f.endswith('.jpg'):\n",
    "            if num_iter == 0:\n",
    "                src = difnet_args.InputBasePath\n",
    "            else:\n",
    "                src = difnet_args.temp_file\n",
    "            # end\n",
    "\n",
    "            if idx < difnet_args.skip or idx > (len(frameList)-1-difnet_args.skip):\n",
    "                skip = 1\n",
    "            else:\n",
    "                skip = difnet_args.skip\n",
    "\n",
    "\n",
    "            fr_g1 = torch.cuda.FloatTensor(np.array(Image.open(difnet_args.temp_file + '%03d.jpg' % (\n",
    "                int(f[:-4])-skip)).resize((difnet_args.desiredWidth, difnet_args.desiredHeight))).transpose(2, 0, 1).astype(np.float32)[None, :, :, :] / 255.0)\n",
    "\n",
    "            fr_g3 = torch.cuda.FloatTensor(np.array(Image.open(\n",
    "                src + '%03d.jpg' % (int(f[:-4])+skip)).resize((difnet_args.desiredWidth, difnet_args.desiredHeight))).transpose(2, 0, 1).astype(np.float32)[None, :, :, :] / 255.0)\n",
    "\n",
    "\n",
    "            fr_o2 = torch.cuda.FloatTensor(np.array(Image.open(\n",
    "                difnet_args.InputBasePath + f).resize((difnet_args.desiredWidth, difnet_args.desiredHeight))).transpose(2, 0, 1).astype(np.float32)[None, :, :, :] / 255.0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fhat, I_int = DIFNet(fr_g1, fr_g3, fr_o2,\n",
    "                                     fr_g3, fr_g1, 0.5)  # Notice 0.5\n",
    "\n",
    "            # Save image\n",
    "            img = Image.fromarray(\n",
    "                np.uint8(fhat.cpu().squeeze().permute(1, 2, 0)*255))\n",
    "            img.save(difnet_args.temp_file + f)\n",
    "\n",
    "            sys.stdout.write('\\rFrame: ' + str(idx) +\n",
    "                             '/' + str(len(frameList)-2))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            idx += 1\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "frame_rate = 25\n",
    "frame_width = difnet_args.desiredWidth\n",
    "frame_height = difnet_args.desiredHeight\n",
    "\n",
    "print()\n",
    "print(\"generate stabilized video...\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter(difnet_args.OutputBasePath + '/tmp_DUT_stable.mp4', fourcc, frame_rate, (frame_width, frame_height))\n",
    "\n",
    "for f in frameList:\n",
    "    if f.endswith('.jpg'):\n",
    "        img = cv2.imread(os.path.join(difnet_args.temp_file, f))\n",
    "        out.write(img)\n",
    "\n",
    "out.release()\n",
    "\n",
    "# OpenCV doesn't ship with the H264 codec that you need to see the video in a notebook; due to licensing incompatabilities. For that reason \n",
    "# I encode as MP4V and then I post process with FFMPEG\n",
    "video_name =os.path.join(difnet_args.OutputBasePath,'DIFRINT_stable.mp4')\n",
    "tmp_video_name = os.path.join(difnet_args.OutputBasePath,'tmp_DUT_stable.mp4')\n",
    "\n",
    "if os.path.exists(video_name):\n",
    "    os.remove(video_name)\n",
    "\n",
    "!ffmpeg-4.4-amd64-static/ffmpeg -i {tmp_video_name} -c:v h264 {video_name}\n",
    "    \n",
    "if os.path.exists(tmp_video_name):\n",
    "    os.remove(tmp_video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table>\n",
       "  <tr>\n",
       "    <td>\n",
       "        <center>Full Unstable (640x360)</center>\n",
       "        <video width=\"640\" height=\"360\" controls autoplay>\n",
       "            <source src=\"unstable.mp4\" type=\"video/mp4\">\n",
       "        </video>\n",
       "    </td>\n",
       "  <tr>\n",
       "    <td>\n",
       "        <center>Stabalized (640x480)</center>\n",
       "        <video width=\"640\" height=\"480\" controls autoplay>\n",
       "          <source src=\"results/DIFRINT_stable.mp4\" type=\"video/mp4\">\n",
       "        </video>\n",
       "    </td>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>\n",
    "        <center>Full Unstable (640x360)</center>\n",
    "        <video width=\"640\" height=\"360\" controls autoplay>\n",
    "            <source src=\"unstable.mp4\" type=\"video/mp4\">\n",
    "        </video>\n",
    "    </td>\n",
    "  <tr>\n",
    "    <td>\n",
    "        <center>Stabalized (640x480)</center>\n",
    "        <video width=\"640\" height=\"480\" controls autoplay>\n",
    "          <source src=\"results/DIFRINT_stable.mp4\" type=\"video/mp4\">\n",
    "        </video>\n",
    "    </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side by Side Qualitative Stabalized Analysis Comparison\n",
    "\n",
    "The follow cell generates a side by side comparison to get a qualitative feel for the output. This notebook could be adjusted to send different video types through (hand tracked star feild imaging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table>\n",
       "  <tr>\n",
       "    <td>\n",
       "        <center>Full Unstable (640x360)</center>\n",
       "        <video width=\"320\" height=\"180\" controls autoplay>\n",
       "            <source src=\"unstable.mp4\" type=\"video/mp4\">\n",
       "        </video>\n",
       "    </td>\n",
       "    <td>\n",
       "        <center>Clipped Unstabalized (342x206)</center>\n",
       "        <video width=\"342\" height=\"206\" controls autoplay>\n",
       "          <source src=\"clipped_unstable.mp4\" type=\"video/mp4\">\n",
       "        </video>\n",
       "    </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>\n",
       "        <center>StabNet Stalization (342x206)</center>\n",
       "        <video width=\"342\" height=\"206\" controls autoplay>\n",
       "          <source src=\"results/StabNet_stable.mp4\" type=\"video/mp4\">\n",
       "        </video>\n",
       "    </td>\n",
       "    <td>\n",
       "        <center>DIFRINT Stabalization (640x480)</center>\n",
       "        <video width=\"320\" height=\"240\" controls autoplay>\n",
       "          <source src=\"results/DIFRINT_stable.mp4\" type=\"video/mp4\">\n",
       "        </video>\n",
       "    </td>\n",
       "    <td>\n",
       "        <center>DUT Stabalization (640x480)</center>\n",
       "        <video width=\"320\" height=\"240\" controls autoplay>\n",
       "          <source src=\"results/DUT_stable.mp4\" type=\"video/mp4\">\n",
       "        </video>\n",
       "    </td>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>\n",
    "        <center>Full Unstable (640x360)</center>\n",
    "        <video width=\"320\" height=\"180\" controls autoplay>\n",
    "            <source src=\"unstable.mp4\" type=\"video/mp4\">\n",
    "        </video>\n",
    "    </td>\n",
    "    <td>\n",
    "        <center>Clipped Unstabalized (342x206)</center>\n",
    "        <video width=\"342\" height=\"206\" controls autoplay>\n",
    "          <source src=\"clipped_unstable.mp4\" type=\"video/mp4\">\n",
    "        </video>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>\n",
    "        <center>StabNet Stalization (342x206)</center>\n",
    "        <video width=\"342\" height=\"206\" controls autoplay>\n",
    "          <source src=\"results/StabNet_stable.mp4\" type=\"video/mp4\">\n",
    "        </video>\n",
    "    </td>\n",
    "    <td>\n",
    "        <center>DIFRINT Stabalization (640x480)</center>\n",
    "        <video width=\"320\" height=\"240\" controls autoplay>\n",
    "          <source src=\"results/DIFRINT_stable.mp4\" type=\"video/mp4\">\n",
    "        </video>\n",
    "    </td>\n",
    "    <td>\n",
    "        <center>DUT Stabalization (640x480)</center>\n",
    "        <video width=\"320\" height=\"240\" controls autoplay>\n",
    "          <source src=\"results/DUT_stable.mp4\" type=\"video/mp4\">\n",
    "        </video>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the side by side comparison you can see that StabNet and DIFRINT both contain artifacts or distortions to the image. DUT stabilization appears to stabalize (watch the blue line towards the end of the video) without distortion.\n",
    "\n",
    "All have a degree of loss of the original image data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the Quantitaive numbers from the DUT Stabilization paper (Dec 2020). The quantitative analysis is noted but reproduction of the analysis is seen as being unnecessary for a model to model comparison. The DUT model out performs the two ML Models (DIFRINT and StabNet). It also outperforms the algortimic approaches of Meshflow and SubSpace. In addition DUT is tuneable by the number of smoothing iterations to deal with video that deal with differences in homography of videos (number of planes of motion).   \n",
    "\n",
    "### Experiment Settings\n",
    "Unstable videos from DeepStab were used for training. Five categories of unstable videos from were used as the test set. The metrics introduced in were used for quantitative evaluation, including cropping ratio, distortion, and stability. Cropping ratio measures the ratio of remaining area and distortion measures the distortion level after stabilization. Stability measures how stable a video is by frequency domain analysis. All the metrics are in the range of [0, 1]. A larger value denotes a better performance. More implementation details, user study results, and robustness evaluation can be found in the supplementary material.\n",
    "\n",
    "The DUT paper does reference the follow method for collecting benchmarks: \"HBundled Camera Paths for Video Stabilization\" (https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/Stabilization_SIGGRAPH13.pdf)\n",
    "\n",
    "### Quantitative Results\n",
    "#### <center> Stability scores of different methods </center>\n",
    "\n",
    "|          | Regular | Parallax | Running | QuickRot |   Crowd  |   Avg.   |\n",
    "|----------|:-------:|:--------:|:-------:|:--------:|:--------:|:--------:|\n",
    "| Meshflow | 0.843 | 0.793 | 0.839 | 0.801 | 0.774 | 0.810\n",
    "| SubSpace | 0.837 | 0.760 | 0.829 |   \\   | 0.730 | 0.789*\n",
    "| DIFRINT | 0.838 | 0.808 | 0.822 | 0.835 | 0.791 | 0.819\n",
    "| StabNet | 0.838 | 0.769 | 0.818 | 0.785 | 0.741 | 0.790\n",
    "| DUT | 0.843 | 0.813 | 0.841 | 0.877 | 0.792 | 0.833\n",
    "\n",
    "<center> ∗ The average score is not accurate since SubSpace fails to stabilize some of the videos in the category of Quick Rotation. </center>\n",
    "\n",
    "#### <center> Distortion scores of different methods </center>\n",
    "\n",
    "|          | Regular | Parallax | Running | QuickRot |   Crowd  |   Avg.   |\n",
    "|----------|:-------:|:--------:|:-------:|:--------:|:--------:|:--------:|\n",
    "| Meshflow | 0.898 | 0.716 | 0.764 | 0.763 | 0.756 | 0.779\n",
    "| SubSpace | 0.973 | 0.855 | 0.939 | \\ | 0.831 | 0.900\n",
    "| DIFRINT | 0.934 | 0.921 | 0.873 | 0.633 | 0.905 | 0.853\n",
    "| StabNet | 0.702 | 0.573 | 0.753 | 0.574 | 0.759 | 0.672\n",
    "| DUT | 0.982 | 0.949 | 0.927 | 0.935 | 0.955 | 0.949 \n",
    "\n",
    "#### <center> Cropping ratios of different methods </center>\n",
    "\n",
    "|          | Regular | Parallax | Running | QuickRot |   Crowd  |   Avg.   |\n",
    "|----------|:-------:|:--------:|:-------:|:--------:|:--------:|:--------:|\n",
    "| Meshflow | 0.686 | 0.540 | 0.584 | 0.376 | 0.552 | 0.548\n",
    "| SubSpace | 0.712 | 0.617 | 0.686 | \\ | 0.543 | 0.639\n",
    "| DIFRINT | 0.922 | 0.903 | 0.869 | 0.732 | 0.882 | 0.862\n",
    "| StabNet | 0.537 | 0.503 | 0.512 | 0.418 | 0.497 | 0.493\n",
    "| DUT | 0.736 | 0.709 | 0.690 | 0.673 | 0.710 | 0.704"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
